{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5667efd7",
   "metadata": {},
   "source": [
    "# ğŸŸ æµ·æ´‹é±¼ç±»è¯†åˆ«æ¨¡å‹ - Colabè®­ç»ƒç‰ˆ\n",
    "\n",
    "æœ¬notebookä¸“ä¸ºGoogle Colabè®¾è®¡ï¼Œç”¨äºè®­ç»ƒæµ·æ´‹é±¼ç±»å•é±¼è¯†åˆ«æ¨¡å‹ã€‚\n",
    "\n",
    "## ğŸ“‹ è®­ç»ƒè®¡åˆ’\n",
    "1. **ç¯å¢ƒè®¾ç½®**: é…ç½®GPUã€å®‰è£…ä¾èµ–\n",
    "2. **æ•°æ®å‡†å¤‡**: ä¸Šä¼ å’Œå¤„ç†å¢å¼ºæ•°æ®é›†\n",
    "3. **æ¨¡å‹è®­ç»ƒ**: ä½¿ç”¨EfficientNet/ResNetè¿›è¡Œè¿ç§»å­¦ä¹ \n",
    "4. **æ€§èƒ½è¯„ä¼°**: éªŒè¯æ¨¡å‹æ•ˆæœ\n",
    "5. **æ¨¡å‹å¯¼å‡º**: ä¿å­˜ç”¨äºéƒ¨ç½²çš„æ¨¡å‹\n",
    "\n",
    "## âš¡ ä½¿ç”¨å‰å‡†å¤‡\n",
    "- ç¡®ä¿å¯ç”¨GPUè¿è¡Œæ—¶ (Runtime â†’ Change runtime type â†’ GPU)\n",
    "- å‡†å¤‡å¥½å¢å¼ºæ•°æ®é›†çš„å‹ç¼©åŒ…\n",
    "- é¢„è®¡è®­ç»ƒæ—¶é—´: 2-4å°æ—¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856d536b",
   "metadata": {},
   "source": [
    "## ğŸ”§ é¡¹ç›®è®¾ç½®\n",
    "\n",
    "### ä»GitHubå…‹éš†é¡¹ç›®\n",
    "æœ¬notebookä¼šè‡ªåŠ¨ä»GitHubå…‹éš†æµ·æ´‹é±¼ç±»è¯†åˆ«é¡¹ç›®åˆ°Google Driveï¼Œç¡®ä¿æ•°æ®å’Œä»£ç çš„æŒä¹…ä¿å­˜ã€‚\n",
    "\n",
    "**ä½¿ç”¨æ­¥éª¤ï¼š**\n",
    "1. è¿è¡Œä¸‹æ–¹ä»£ç æŒ‚è½½Google Drive\n",
    "2. è‡ªåŠ¨å…‹éš†é¡¹ç›®åˆ°Driveä¸­\n",
    "3. è®¾ç½®å·¥ä½œç›®å½•å¹¶å¼€å§‹è®­ç»ƒ\n",
    "\n",
    "**æ³¨æ„ï¼š** è¯·ç¡®ä¿æ‚¨æœ‰è¶³å¤Ÿçš„Driveç©ºé—´ï¼ˆå»ºè®®5GBä»¥ä¸Šï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6460aae4",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒè®¾ç½®å’ŒGPUæ£€æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006b5bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === æ­¥éª¤1: æŒ‚è½½Google Drive ===\n",
    "from google.colab import drive\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "# æŒ‚è½½Google Drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"âœ… Google Drive æŒ‚è½½æˆåŠŸ\")\n",
    "\n",
    "# è®¾ç½®é¡¹ç›®è·¯å¾„\n",
    "DRIVE_ROOT = \"/content/drive/MyDrive\"\n",
    "PROJECT_DIR = f\"{DRIVE_ROOT}/MarineFish_recognition\"\n",
    "GITHUB_REPO = \"YOUR_USERNAME/marine-fish-recognition\"  # ğŸ”´ è¯·æ›¿æ¢ä¸ºå®é™…çš„GitHubä»“åº“åœ°å€\n",
    "\n",
    "print(f\"é¡¹ç›®å°†ä¿å­˜åˆ°: {PROJECT_DIR}\")\n",
    "\n",
    "# === æ­¥éª¤2: å…‹éš†æˆ–æ›´æ–°é¡¹ç›® ===\n",
    "def clone_or_update_project():\n",
    "    \"\"\"ä»GitHubå…‹éš†æˆ–æ›´æ–°é¡¹ç›®åˆ°Google Drive\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(PROJECT_DIR):\n",
    "            print(\"ğŸ”„ é¡¹ç›®ç›®å½•å·²å­˜åœ¨ï¼Œæ›´æ–°é¡¹ç›®...\")\n",
    "            os.chdir(PROJECT_DIR)\n",
    "            # æ‹‰å–æœ€æ–°æ›´æ”¹\n",
    "            result = subprocess.run([\"git\", \"pull\"], capture_output=True, text=True)\n",
    "            if result.returncode == 0:\n",
    "                print(\"âœ… é¡¹ç›®æ›´æ–°æˆåŠŸ\")\n",
    "            else:\n",
    "                print(f\"âš ï¸  é¡¹ç›®æ›´æ–°å¤±è´¥: {result.stderr}\")\n",
    "        else:\n",
    "            print(\"ğŸ“¥ ä»GitHubå…‹éš†é¡¹ç›®...\")\n",
    "            os.chdir(DRIVE_ROOT)\n",
    "            # å…‹éš†é¡¹ç›®\n",
    "            result = subprocess.run([\n",
    "                \"git\", \"clone\", \n",
    "                f\"https://github.com/{GITHUB_REPO}.git\",\n",
    "                \"MarineFish_recognition\"\n",
    "            ], capture_output=True, text=True)\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                print(\"âœ… é¡¹ç›®å…‹éš†æˆåŠŸ\")\n",
    "            else:\n",
    "                print(f\"âŒ é¡¹ç›®å…‹éš†å¤±è´¥: {result.stderr}\")\n",
    "                print(\"è¯·æ£€æŸ¥GitHubä»“åº“åœ°å€æ˜¯å¦æ­£ç¡®\")\n",
    "                return False\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ é¡¹ç›®è®¾ç½®å¤±è´¥: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# æ‰§è¡Œé¡¹ç›®å…‹éš†/æ›´æ–°\n",
    "success = clone_or_update_project()\n",
    "\n",
    "if success:\n",
    "    # åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•\n",
    "    os.chdir(PROJECT_DIR)\n",
    "    print(f\"ğŸ“‚ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\")\n",
    "    \n",
    "    # æ£€æŸ¥é¡¹ç›®ç»“æ„\n",
    "    if os.path.exists(\"fish_backbone\"):\n",
    "        print(\"âœ… é¡¹ç›®ç»“æ„æ£€æŸ¥é€šè¿‡\")\n",
    "        print(\"ğŸ“ å‘ç°ä»¥ä¸‹å…³é”®ç›®å½•:\")\n",
    "        for item in [\"fish_backbone\", \"compact_dataset\", \"dataset\", \"fish_backbone/mini_dataset\"]:\n",
    "            if os.path.exists(item):\n",
    "                print(f\"   âœ… {item}\")\n",
    "            else:\n",
    "                print(f\"   âš ï¸  {item} (æœªæ‰¾åˆ°)\")\n",
    "    else:\n",
    "        print(\"âŒ é¡¹ç›®ç»“æ„å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥GitHubä»“åº“\")\n",
    "else:\n",
    "    print(\"âŒ æ— æ³•ç»§ç»­ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒGitHubä»“åº“è®¾ç½®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d5e624",
   "metadata": {},
   "source": [
    "## 2. ä»GitHubå…‹éš†é¡¹ç›®å’Œæ•°æ®é›†\n",
    "\n",
    "### æ–¹æ¡ˆA: ä»GitHubå…‹éš†å®Œæ•´é¡¹ç›®ï¼ˆæ¨èï¼‰\n",
    "1. å°†æ•´ä¸ªé¡¹ç›®ï¼ˆåŒ…æ‹¬å¢å¼ºæ•°æ®é›†ï¼‰ä¸Šä¼ åˆ°GitHub\n",
    "2. åœ¨Colabä¸­ç›´æ¥å…‹éš†å’Œä½¿ç”¨\n",
    "\n",
    "### æ–¹æ¡ˆB: æŒ‚è½½Google Drive\n",
    "1. å°†æ•°æ®é›†ä¸Šä¼ åˆ°Google Drive\n",
    "2. åœ¨Colabä¸­æŒ‚è½½Driveè®¿é—®æ•°æ®\n",
    "\n",
    "é€‰æ‹©ä¸‹é¢å¯¹åº”çš„ä»£ç å—æ‰§è¡Œï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14255fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ–¹æ¡ˆA: ä»GitHubå…‹éš†é¡¹ç›® (æ¨è)\n",
    "def clone_from_github():\n",
    "    \"\"\"ä»GitHubå…‹éš†é¡¹ç›®\"\"\"\n",
    "    \n",
    "    # æ›¿æ¢ä¸ºæ‚¨çš„GitHubä»“åº“URL\n",
    "    GITHUB_REPO_URL = \"https://github.com/YOUR_USERNAME/MarineFish_recognition.git\"\n",
    "    PROJECT_NAME = \"MarineFish_recognition\"\n",
    "    \n",
    "    print(\"ğŸ“¥ ä»GitHubå…‹éš†é¡¹ç›®...\")\n",
    "    \n",
    "    # å…‹éš†ä»“åº“\n",
    "    if not os.path.exists(PROJECT_NAME):\n",
    "        print(f\"ğŸ”„ æ­£åœ¨å…‹éš†: {GITHUB_REPO_URL}\")\n",
    "        !git clone {GITHUB_REPO_URL}\n",
    "        print(f\"âœ… é¡¹ç›®å…‹éš†å®Œæˆ: {PROJECT_NAME}\")\n",
    "    else:\n",
    "        print(f\"ğŸ“ é¡¹ç›®å·²å­˜åœ¨: {PROJECT_NAME}\")\n",
    "        # æ‹‰å–æœ€æ–°æ›´æ”¹\n",
    "        !cd {PROJECT_NAME} && git pull\n",
    "        print(\"âœ… é¡¹ç›®å·²æ›´æ–°åˆ°æœ€æ–°ç‰ˆæœ¬\")\n",
    "    \n",
    "    # è‡ªåŠ¨æ£€æµ‹æ•°æ®é›†\n",
    "    return auto_detect_dataset(PROJECT_NAME)\n",
    "\n",
    "# æ–¹æ¡ˆB: æŒ‚è½½Google Drive\n",
    "def mount_google_drive():\n",
    "    \"\"\"æŒ‚è½½Google Driveå¹¶è®¿é—®æ•°æ®é›†\"\"\"\n",
    "    \n",
    "    print(\"ğŸ“± æŒ‚è½½Google Drive...\")\n",
    "    \n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # æ•°æ®é›†åœ¨Driveä¸­çš„è·¯å¾„ (è¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹)\n",
    "    drive_dataset_path = \"/content/drive/MyDrive/MarineFish_Dataset/augmented_dataset\"\n",
    "    \n",
    "    if os.path.exists(drive_dataset_path):\n",
    "        print(\"âœ… Google DriveæŒ‚è½½æˆåŠŸï¼Œæ‰¾åˆ°æ•°æ®é›†\")\n",
    "        \n",
    "        classes = [d for d in os.listdir(drive_dataset_path) \n",
    "                  if os.path.isdir(os.path.join(drive_dataset_path, d)) and not d.startswith('.')]\n",
    "        \n",
    "        print(f\"ğŸ“Š å‘ç° {len(classes)} ä¸ªé±¼ç±»ç±»åˆ«\")\n",
    "        return True, classes, drive_dataset_path\n",
    "    else:\n",
    "        print(\"âŒ æœªåœ¨Google Driveä¸­æ‰¾åˆ°æ•°æ®é›†\")\n",
    "        print(f\"è¯·ç¡®ä¿æ•°æ®é›†åœ¨: {drive_dataset_path}\")\n",
    "        return False, [], \"\"\n",
    "\n",
    "# é€‰æ‹©ä½¿ç”¨çš„æ–¹æ¡ˆ\n",
    "USE_GITHUB = True  # è®¾ç½®ä¸ºTrueä½¿ç”¨GitHubï¼ŒFalseä½¿ç”¨Google Drive\n",
    "\n",
    "print(\"ğŸš€ å¼€å§‹æ•°æ®é›†å‡†å¤‡...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if USE_GITHUB:\n",
    "    print(\"ğŸ“‚ ä½¿ç”¨æ–¹æ¡ˆA: GitHubå…‹éš†\")\n",
    "    print(\"âš ï¸  è¯·å…ˆä¿®æ”¹ä¸Šé¢çš„GITHUB_REPO_URLä¸ºæ‚¨çš„ä»“åº“åœ°å€\")\n",
    "    success, class_names, data_path = clone_from_github()\n",
    "else:\n",
    "    print(\"ğŸ“‚ ä½¿ç”¨æ–¹æ¡ˆB: Google Drive\")\n",
    "    success, class_names, data_path = mount_google_drive()\n",
    "\n",
    "if success:\n",
    "    print(\"\\nğŸ¯ æ•°æ®é›†å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒï¼\")\n",
    "    NUM_CLASSES = len(class_names)\n",
    "    print(f\"åˆ†ç±»ç±»åˆ«æ•°: {NUM_CLASSES}\")\n",
    "    \n",
    "    # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡\n",
    "    total_images = 0\n",
    "    print(f\"\\nğŸ“Š æ•°æ®é›†è¯¦æƒ…:\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_path = os.path.join(data_path, class_name)\n",
    "        if os.path.exists(class_path):\n",
    "            count = len([f for f in os.listdir(class_path) \n",
    "                        if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "            total_images += count\n",
    "            if i < 10:  # åªæ˜¾ç¤ºå‰10ä¸ªç±»åˆ«\n",
    "                print(f\"  {i+1:2d}. {class_name:25s} - {count:3d} å¼ \")\n",
    "    \n",
    "    if len(class_names) > 10:\n",
    "        print(f\"  ... è¿˜æœ‰ {len(class_names)-10} ä¸ªç±»åˆ«\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ æ€»è®¡: {total_images} å¼ å›¾ç‰‡\")\n",
    "    print(f\"å¹³å‡æ¯ç±»: {total_images // len(class_names)} å¼ \")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nâš ï¸  æ•°æ®é›†å‡†å¤‡å¤±è´¥ï¼Œè¯·æ£€æŸ¥:\")\n",
    "    if USE_GITHUB:\n",
    "        print(\"1. GitHubä»“åº“URLæ˜¯å¦æ­£ç¡®\")\n",
    "        print(\"2. ä»“åº“æ˜¯å¦åŒ…å«æ•°æ®é›† (augmented_dataset æˆ– compact_dataset.zip)\")\n",
    "        print(\"3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\")\n",
    "    else:\n",
    "        print(\"1. Google Driveæ˜¯å¦å·²æˆæƒ\")\n",
    "        print(\"2. æ•°æ®é›†è·¯å¾„æ˜¯å¦æ­£ç¡®\")\n",
    "        print(\"3. æ•°æ®é›†æ˜¯å¦å·²ä¸Šä¼ åˆ°Drive\")\n",
    "\n",
    "# === æ­¥éª¤3: å®‰è£…ä¾èµ– ===\n",
    "import sys\n",
    "\n",
    "# ç¡®ä¿åœ¨é¡¹ç›®ç›®å½•ä¸­\n",
    "if not os.path.exists(\"fish_backbone\"):\n",
    "    print(\"âŒ è¯·å…ˆè¿è¡Œä¸Šé¢çš„ä»£ç å…‹éš†é¡¹ç›®\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"ğŸ“¦ å®‰è£…Pythonä¾èµ–åŒ…...\")\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦æœ‰requirements.txt\n",
    "requirements_files = [\n",
    "    \"fish_backbone/requirements.txt\",\n",
    "    \"requirements.txt\"\n",
    "]\n",
    "\n",
    "requirements_file = None\n",
    "for req_file in requirements_files:\n",
    "    if os.path.exists(req_file):\n",
    "        requirements_file = req_file\n",
    "        break\n",
    "\n",
    "if requirements_file:\n",
    "    print(f\"ğŸ“‹ ä½¿ç”¨ {requirements_file} å®‰è£…ä¾èµ–\")\n",
    "    result = subprocess.run([\n",
    "        sys.executable, \"-m\", \"pip\", \"install\", \"-r\", requirements_file\n",
    "    ], capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"âœ… ä¾èµ–å®‰è£…æˆåŠŸ\")\n",
    "    else:\n",
    "        print(f\"âš ï¸  éƒ¨åˆ†ä¾èµ–å®‰è£…å¤±è´¥: {result.stderr}\")\n",
    "        print(\"å°è¯•æ‰‹åŠ¨å®‰è£…æ ¸å¿ƒä¾èµ–...\")\n",
    "        \n",
    "        # æ‰‹åŠ¨å®‰è£…æ ¸å¿ƒä¾èµ–\n",
    "        core_packages = [\n",
    "            \"torch\", \"torchvision\", \"torchaudio\",\n",
    "            \"pillow\", \"numpy\", \"matplotlib\",\n",
    "            \"opencv-python\", \"scikit-learn\",\n",
    "            \"tqdm\", \"flask\"\n",
    "        ]\n",
    "        \n",
    "        for package in core_packages:\n",
    "            print(f\"å®‰è£… {package}...\")\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", package], \n",
    "                         capture_output=True, text=True)\n",
    "else:\n",
    "    print(\"ğŸ“‹ æœªæ‰¾åˆ°requirements.txtï¼Œå®‰è£…åŸºç¡€ä¾èµ–...\")\n",
    "    # åŸºç¡€ä¾èµ–åˆ—è¡¨\n",
    "    packages = [\n",
    "        \"torch\", \"torchvision\", \"torchaudio\",\n",
    "        \"pillow\", \"numpy\", \"matplotlib\", \"opencv-python\",\n",
    "        \"scikit-learn\", \"tqdm\", \"flask\", \"requests\"\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        print(f\"å®‰è£… {package}...\")\n",
    "        result = subprocess.run([\n",
    "            sys.executable, \"-m\", \"pip\", \"install\", package\n",
    "        ], capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"âœ… {package} å®‰è£…æˆåŠŸ\")\n",
    "        else:\n",
    "            print(f\"âš ï¸  {package} å®‰è£…å¤±è´¥\")\n",
    "\n",
    "print(\"ğŸ¯ æ£€æŸ¥GPUå¯ç”¨æ€§...\")\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"âœ… GPUå¯ç”¨: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"   GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    else:\n",
    "        print(\"âš ï¸  GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸  PyTorchæœªæ­£ç¡®å®‰è£…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9daa9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ–¹æ¡ˆC: å¤„ç†GitHubä¸Šçš„ç´§å‡‘æ•°æ®é›† (é€‚åˆè¾ƒå°é¡¹ç›®)\n",
    "def extract_compact_dataset(project_dir):\n",
    "    \"\"\"è§£å‹GitHubé¡¹ç›®ä¸­çš„ç´§å‡‘æ•°æ®é›†\"\"\"\n",
    "    \n",
    "    compact_zip = os.path.join(project_dir, \"compact_dataset.zip\")\n",
    "    \n",
    "    if os.path.exists(compact_zip):\n",
    "        print(\"ğŸ“¦ å‘ç°ç´§å‡‘æ•°æ®é›†å‹ç¼©åŒ…ï¼Œå¼€å§‹è§£å‹...\")\n",
    "        \n",
    "        import zipfile\n",
    "        with zipfile.ZipFile(compact_zip, 'r') as zip_ref:\n",
    "            zip_ref.extractall(project_dir)\n",
    "        \n",
    "        dataset_path = os.path.join(project_dir, \"compact_dataset\")\n",
    "        \n",
    "        if os.path.exists(dataset_path):\n",
    "            classes = [d for d in os.listdir(dataset_path) \n",
    "                      if os.path.isdir(os.path.join(dataset_path, d)) and not d.startswith('.')]\n",
    "            \n",
    "            print(f\"âœ… ç´§å‡‘æ•°æ®é›†è§£å‹å®Œæˆ\")\n",
    "            print(f\"ğŸ“Š å‘ç° {len(classes)} ä¸ªé±¼ç±»ç±»åˆ«\")\n",
    "            \n",
    "            # ç»Ÿè®¡å›¾ç‰‡æ•°é‡\n",
    "            total_images = 0\n",
    "            for class_name in classes[:5]:\n",
    "                class_path = os.path.join(dataset_path, class_name)\n",
    "                count = len([f for f in os.listdir(class_path) \n",
    "                            if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "                total_images += count\n",
    "                print(f\"  - {class_name}: {count} å¼ å›¾ç‰‡\")\n",
    "            \n",
    "            if len(classes) > 5:\n",
    "                print(f\"  ... è¿˜æœ‰ {len(classes)-5} ä¸ªç±»åˆ«\")\n",
    "            \n",
    "            print(f\"ğŸ“ˆ æ€»è®¡: çº¦ {total_images * len(classes) // 5} å¼ å›¾ç‰‡\")\n",
    "            \n",
    "            return True, classes, dataset_path\n",
    "        else:\n",
    "            print(\"âŒ è§£å‹åæœªæ‰¾åˆ°æ•°æ®é›†ç›®å½•\")\n",
    "            return False, [], \"\"\n",
    "    else:\n",
    "        print(\"âŒ æœªæ‰¾åˆ°ç´§å‡‘æ•°æ®é›†å‹ç¼©åŒ…\")\n",
    "        return False, [], \"\"\n",
    "\n",
    "# è‡ªåŠ¨æ£€æµ‹æ•°æ®é›†ç±»å‹\n",
    "def auto_detect_dataset(project_dir):\n",
    "    \"\"\"è‡ªåŠ¨æ£€æµ‹å¯ç”¨çš„æ•°æ®é›†\"\"\"\n",
    "    \n",
    "    # æ£€æŸ¥å®Œæ•´å¢å¼ºæ•°æ®é›†\n",
    "    full_dataset = os.path.join(project_dir, \"augmented_dataset\")\n",
    "    if os.path.exists(full_dataset):\n",
    "        print(\"ğŸ¯ æ‰¾åˆ°å®Œæ•´å¢å¼ºæ•°æ®é›†\")\n",
    "        classes = [d for d in os.listdir(full_dataset) \n",
    "                  if os.path.isdir(os.path.join(full_dataset, d)) and not d.startswith('.')]\n",
    "        return True, classes, full_dataset\n",
    "    \n",
    "    # æ£€æŸ¥ç´§å‡‘æ•°æ®é›†å‹ç¼©åŒ…\n",
    "    compact_zip = os.path.join(project_dir, \"compact_dataset.zip\")\n",
    "    if os.path.exists(compact_zip):\n",
    "        print(\"ğŸ“¦ æ‰¾åˆ°ç´§å‡‘æ•°æ®é›†å‹ç¼©åŒ…\")\n",
    "        return extract_compact_dataset(project_dir)\n",
    "    \n",
    "    # æ£€æŸ¥å·²è§£å‹çš„ç´§å‡‘æ•°æ®é›†\n",
    "    compact_dataset = os.path.join(project_dir, \"compact_dataset\")\n",
    "    if os.path.exists(compact_dataset):\n",
    "        print(\"ğŸ“ æ‰¾åˆ°ç´§å‡‘æ•°æ®é›†ç›®å½•\")\n",
    "        classes = [d for d in os.listdir(compact_dataset) \n",
    "                  if os.path.isdir(os.path.join(compact_dataset, d)) and not d.startswith('.')]\n",
    "        return True, classes, compact_dataset\n",
    "    \n",
    "    print(\"âŒ æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„æ•°æ®é›†\")\n",
    "    return False, [], \"\"\n",
    "\n",
    "# === æ­¥éª¤4: é€‰æ‹©æ•°æ®é›† ===\n",
    "import json\n",
    "\n",
    "print(\"ğŸ¯ æ£€æµ‹å¯ç”¨æ•°æ®é›†...\")\n",
    "\n",
    "# æ£€æŸ¥å¯ç”¨çš„æ•°æ®é›†\n",
    "available_datasets = {}\n",
    "\n",
    "# æ£€æŸ¥å®Œæ•´æ•°æ®é›†\n",
    "if os.path.exists(\"dataset\"):\n",
    "    dataset_size = len([f for f in os.listdir(\"dataset\") if os.path.isdir(os.path.join(\"dataset\", f))])\n",
    "    available_datasets[\"å®Œæ•´æ•°æ®é›†\"] = {\n",
    "        \"path\": \"dataset\",\n",
    "        \"classes\": dataset_size,\n",
    "        \"description\": \"å®Œæ•´çš„æµ·æ´‹é±¼ç±»æ•°æ®é›†ï¼Œç±»åˆ«æœ€å¤šä½†è®­ç»ƒæ—¶é—´è¾ƒé•¿\"\n",
    "    }\n",
    "\n",
    "# æ£€æŸ¥ç´§å‡‘æ•°æ®é›†\n",
    "if os.path.exists(\"compact_dataset\"):\n",
    "    compact_size = len([f for f in os.listdir(\"compact_dataset\") if os.path.isdir(os.path.join(\"compact_dataset\", f))])\n",
    "    available_datasets[\"ç´§å‡‘æ•°æ®é›†\"] = {\n",
    "        \"path\": \"compact_dataset\", \n",
    "        \"classes\": compact_size,\n",
    "        \"description\": \"ç²¾é€‰çš„ç´§å‡‘æ•°æ®é›†ï¼Œå¹³è¡¡äº†æ•°æ®é‡å’Œè®­ç»ƒæ•ˆç‡\"\n",
    "    }\n",
    "\n",
    "# æ£€æŸ¥miniæ•°æ®é›†\n",
    "if os.path.exists(\"fish_backbone/mini_dataset\"):\n",
    "    mini_size = len([f for f in os.listdir(\"fish_backbone/mini_dataset\") if os.path.isdir(os.path.join(\"fish_backbone/mini_dataset\", f))])\n",
    "    available_datasets[\"Miniæ•°æ®é›†\"] = {\n",
    "        \"path\": \"fish_backbone/mini_dataset\",\n",
    "        \"classes\": mini_size, \n",
    "        \"description\": \"å¿«é€Ÿæµ‹è¯•ç”¨çš„å°å‹æ•°æ®é›†ï¼Œè®­ç»ƒé€Ÿåº¦æœ€å¿«\"\n",
    "    }\n",
    "\n",
    "# æ˜¾ç¤ºå¯ç”¨æ•°æ®é›†\n",
    "print(\"ğŸ“Š å¯ç”¨æ•°æ®é›†:\")\n",
    "for name, info in available_datasets.items():\n",
    "    print(f\"   ğŸ”¹ {name}: {info['classes']}ä¸ªç±»åˆ« - {info['description']}\")\n",
    "\n",
    "# === æ•°æ®é›†é€‰æ‹©é…ç½® ===\n",
    "# ğŸ”´ åœ¨è¿™é‡Œé€‰æ‹©è¦ä½¿ç”¨çš„æ•°æ®é›†ç±»å‹\n",
    "DATASET_CHOICE = \"Miniæ•°æ®é›†\"  # å¯é€‰: \"å®Œæ•´æ•°æ®é›†\", \"ç´§å‡‘æ•°æ®é›†\", \"Miniæ•°æ®é›†\"\n",
    "\n",
    "if DATASET_CHOICE not in available_datasets:\n",
    "    print(f\"âŒ é€‰æ‹©çš„æ•°æ®é›† '{DATASET_CHOICE}' ä¸å¯ç”¨\")\n",
    "    print(\"å¯ç”¨é€‰é¡¹:\", list(available_datasets.keys()))\n",
    "    DATASET_CHOICE = list(available_datasets.keys())[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„æ•°æ®é›†\n",
    "    print(f\"ğŸ”„ è‡ªåŠ¨é€‰æ‹©: {DATASET_CHOICE}\")\n",
    "\n",
    "# è®¾ç½®æ•°æ®é›†è·¯å¾„\n",
    "DATASET_PATH = available_datasets[DATASET_CHOICE][\"path\"]\n",
    "NUM_CLASSES = available_datasets[DATASET_CHOICE][\"classes\"]\n",
    "\n",
    "print(f\"\\nâœ… é€‰æ‹©æ•°æ®é›†: {DATASET_CHOICE}\")\n",
    "print(f\"ğŸ“‚ æ•°æ®é›†è·¯å¾„: {DATASET_PATH}\")\n",
    "print(f\"ğŸ·ï¸  ç±»åˆ«æ•°é‡: {NUM_CLASSES}\")\n",
    "\n",
    "# æ£€æŸ¥å¯¹åº”çš„é…ç½®æ–‡ä»¶\n",
    "config_files = {\n",
    "    \"dataset\": \"fish_backbone/dataset_config.json\",\n",
    "    \"compact_dataset\": \"fish_backbone/dataset_config.json\", \n",
    "    \"fish_backbone/mini_dataset\": \"fish_backbone/mini_dataset_config.json\"\n",
    "}\n",
    "\n",
    "config_file = config_files.get(DATASET_PATH)\n",
    "if config_file and os.path.exists(config_file):\n",
    "    print(f\"ğŸ“‹ æ‰¾åˆ°é…ç½®æ–‡ä»¶: {config_file}\")\n",
    "    with open(config_file, 'r', encoding='utf-8') as f:\n",
    "        dataset_config = json.load(f)\n",
    "    print(f\"   ç±»åˆ«æ˜ å°„å·²åŠ è½½: {len(dataset_config.get('class_names', []))}ä¸ªç±»åˆ«\")\n",
    "else:\n",
    "    print(\"âš ï¸  æœªæ‰¾åˆ°å¯¹åº”çš„é…ç½®æ–‡ä»¶ï¼Œå°†åŠ¨æ€ç”Ÿæˆ\")\n",
    "\n",
    "# æ£€æŸ¥æ•°æ®é›†å†…å®¹\n",
    "print(f\"\\nğŸ” æ£€æŸ¥æ•°æ®é›†å†…å®¹...\")\n",
    "if os.path.exists(DATASET_PATH):\n",
    "    classes = [d for d in os.listdir(DATASET_PATH) if os.path.isdir(os.path.join(DATASET_PATH, d))]\n",
    "    print(f\"   å‘ç° {len(classes)} ä¸ªç±»åˆ«:\")\n",
    "    for i, cls in enumerate(sorted(classes)[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ª\n",
    "        sample_count = len(os.listdir(os.path.join(DATASET_PATH, cls)))\n",
    "        print(f\"     {i+1:2d}. {cls}: {sample_count} å¼ å›¾ç‰‡\")\n",
    "    if len(classes) > 10:\n",
    "        print(f\"     ... è¿˜æœ‰ {len(classes)-10} ä¸ªç±»åˆ«\")\n",
    "else:\n",
    "    print(\"âŒ æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb56c02",
   "metadata": {},
   "source": [
    "## 3. æ•°æ®åŠ è½½å™¨å®šä¹‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fabdd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FishDataset(Dataset):\n",
    "    \"\"\"æµ·æ´‹é±¼ç±»æ•°æ®é›†ç±»\"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = sorted([d for d in os.listdir(root_dir) \n",
    "                              if os.path.isdir(os.path.join(root_dir, d)) and not d.startswith('.')])\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        \n",
    "        # æ„å»ºå›¾ç‰‡è·¯å¾„å’Œæ ‡ç­¾åˆ—è¡¨\n",
    "        self.samples = []\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            class_idx = self.class_to_idx[class_name]\n",
    "            \n",
    "            for img_name in os.listdir(class_dir):\n",
    "                if img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.samples.append((img_path, class_idx))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        # åŠ è½½å›¾ç‰‡\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# å®šä¹‰æ•°æ®å˜æ¢\n",
    "def get_transforms():\n",
    "    # è®­ç»ƒæ—¶çš„æ•°æ®å¢å¼º\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # éªŒè¯/æµ‹è¯•æ—¶çš„å˜æ¢\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "# åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨\n",
    "if success:\n",
    "    train_transform, val_transform = get_transforms()\n",
    "    \n",
    "    # åˆ›å»ºå®Œæ•´æ•°æ®é›†\n",
    "    full_dataset = FishDataset(data_path, transform=val_transform)\n",
    "    \n",
    "    # åˆ’åˆ†è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›† (70%, 20%, 10%)\n",
    "    dataset_size = len(full_dataset)\n",
    "    train_size = int(0.7 * dataset_size)\n",
    "    val_size = int(0.2 * dataset_size)\n",
    "    test_size = dataset_size - train_size - val_size\n",
    "    \n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        full_dataset, [train_size, val_size, test_size]\n",
    "    )\n",
    "    \n",
    "    # ä¸ºè®­ç»ƒé›†è®¾ç½®æ•°æ®å¢å¼º\n",
    "    train_dataset.dataset.transform = train_transform\n",
    "    \n",
    "    # åˆ›å»ºæ•°æ®åŠ è½½å™¨\n",
    "    BATCH_SIZE = 32\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    \n",
    "    print(f\"ğŸ“Š æ•°æ®é›†åˆ’åˆ†å®Œæˆ:\")\n",
    "    print(f\"  è®­ç»ƒé›†: {len(train_dataset)} å¼  ({len(train_dataset)/dataset_size*100:.1f}%)\")\n",
    "    print(f\"  éªŒè¯é›†: {len(val_dataset)} å¼  ({len(val_dataset)/dataset_size*100:.1f}%)\")\n",
    "    print(f\"  æµ‹è¯•é›†: {len(test_dataset)} å¼  ({len(test_dataset)/dataset_size*100:.1f}%)\")\n",
    "    print(f\"  æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}\")\n",
    "    \n",
    "    # ä¿å­˜ç±»åˆ«ä¿¡æ¯\n",
    "    class_info = {\n",
    "        'classes': class_names,\n",
    "        'class_to_idx': full_dataset.class_to_idx,\n",
    "        'num_classes': len(class_names)\n",
    "    }\n",
    "    \n",
    "    with open('class_info.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(class_info, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(\"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ\")\n",
    "else:\n",
    "    print(\"âš ï¸  è¯·å…ˆå‡†å¤‡æ•°æ®é›†\")\n",
    "\n",
    "# === æ­¥éª¤5: æ¨¡å‹å®šä¹‰ ===\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°Pythonè·¯å¾„\n",
    "sys.path.append('fish_backbone')\n",
    "\n",
    "print(f\"ğŸ§  å®šä¹‰æ¨¡å‹æ¶æ„ (ç±»åˆ«æ•°: {NUM_CLASSES})\")\n",
    "\n",
    "class FishClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(FishClassifier, self).__init__()\n",
    "        # ä½¿ç”¨é¢„è®­ç»ƒçš„ResNet18ä½œä¸ºéª¨å¹²ç½‘ç»œ\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        \n",
    "        # æ›¿æ¢æœ€åçš„åˆ†ç±»å±‚\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Linear(in_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹å®ä¾‹\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = FishClassifier(num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "print(f\"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ\")\n",
    "print(f\"ğŸ“± è®¾å¤‡: {device}\")\n",
    "print(f\"ğŸ”¢ å‚æ•°æ€»æ•°: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# å®šä¹‰æ•°æ®å˜æ¢\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"ğŸ”„ æ•°æ®å˜æ¢å®šä¹‰å®Œæˆ\")\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦æœ‰é¢„è®­ç»ƒæ¨¡å‹å¯ä»¥åŠ è½½\n",
    "model_files = [\n",
    "    \"fish_backbone/marine_fish_model.pth\",\n",
    "    \"fish_backbone/best_model.pth\",\n",
    "    \"marine_fish_model.pth\"\n",
    "]\n",
    "\n",
    "pretrained_model = None\n",
    "for model_file in model_files:\n",
    "    if os.path.exists(model_file):\n",
    "        pretrained_model = model_file\n",
    "        break\n",
    "\n",
    "if pretrained_model:\n",
    "    try:\n",
    "        print(f\"ğŸ”„ å°è¯•åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {pretrained_model}\")\n",
    "        checkpoint = torch.load(pretrained_model, map_location=device)\n",
    "        \n",
    "        # æ£€æŸ¥æ¨¡å‹ç»“æ„å…¼å®¹æ€§\n",
    "        if hasattr(checkpoint, 'keys') and 'state_dict' in checkpoint:\n",
    "            model_state = checkpoint['state_dict']\n",
    "        else:\n",
    "            model_state = checkpoint\n",
    "            \n",
    "        # æ£€æŸ¥åˆ†ç±»å±‚çš„ç»´åº¦\n",
    "        fc_weight_shape = model_state.get('backbone.fc.weight', model_state.get('fc.weight'))\n",
    "        if fc_weight_shape is not None and fc_weight_shape.shape[0] == NUM_CLASSES:\n",
    "            model.load_state_dict(model_state)\n",
    "            print(\"âœ… é¢„è®­ç»ƒæ¨¡å‹åŠ è½½æˆåŠŸ\")\n",
    "        else:\n",
    "            print(f\"âš ï¸  é¢„è®­ç»ƒæ¨¡å‹ç±»åˆ«æ•°ä¸åŒ¹é… (éœ€è¦: {NUM_CLASSES})ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  é¢„è®­ç»ƒæ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}\")\n",
    "        print(\"ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹\")\n",
    "else:\n",
    "    print(\"ğŸ“ æœªæ‰¾åˆ°é¢„è®­ç»ƒæ¨¡å‹ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef6ef1f",
   "metadata": {},
   "source": [
    "## 4. æ¨¡å‹å®šä¹‰\n",
    "\n",
    "é€‰æ‹©é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œè¿ç§»å­¦ä¹ ã€‚æ¨èä½¿ç”¨EfficientNet-B0ä»¥è·å¾—æœ€ä½³çš„é€Ÿåº¦å’Œç²¾åº¦å¹³è¡¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6011e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…efficientnetï¼ˆå¦‚æœéœ€è¦ï¼‰\n",
    "try:\n",
    "    from efficientnet_pytorch import EfficientNet\n",
    "    print(\"âœ… EfficientNet å·²å®‰è£…\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ“¦ æ­£åœ¨å®‰è£… EfficientNet...\")\n",
    "    !pip install efficientnet_pytorch\n",
    "    from efficientnet_pytorch import EfficientNet\n",
    "    print(\"âœ… EfficientNet å®‰è£…å®Œæˆ\")\n",
    "\n",
    "def create_model(model_name='efficientnet-b0', num_classes=NUM_CLASSES, pretrained=True):\n",
    "    \"\"\"\n",
    "    åˆ›å»ºé¢„è®­ç»ƒæ¨¡å‹\n",
    "    \n",
    "    Args:\n",
    "        model_name: æ¨¡å‹åç§° ('efficientnet-b0', 'resnet50', 'resnet101')\n",
    "        num_classes: åˆ†ç±»ç±»åˆ«æ•°\n",
    "        pretrained: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡\n",
    "    \"\"\"\n",
    "    \n",
    "    if model_name.startswith('efficientnet'):\n",
    "        if pretrained:\n",
    "            model = EfficientNet.from_pretrained(model_name, num_classes=num_classes)\n",
    "        else:\n",
    "            model = EfficientNet.from_name(model_name, num_classes=num_classes)\n",
    "        \n",
    "        print(f\"ğŸ¤– åˆ›å»º {model_name} æ¨¡å‹\")\n",
    "        \n",
    "    elif model_name == 'resnet50':\n",
    "        model = models.resnet50(pretrained=pretrained)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "        print(f\"ğŸ¤– åˆ›å»º ResNet50 æ¨¡å‹\")\n",
    "        \n",
    "    elif model_name == 'resnet101':\n",
    "        model = models.resnet101(pretrained=pretrained)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "        print(f\"ğŸ¤– åˆ›å»º ResNet101 æ¨¡å‹\")\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# æ¨¡å‹é€‰æ‹©\n",
    "MODEL_NAME = 'efficientnet-b0'  # å¯ä»¥æ”¹ä¸º 'resnet50', 'resnet101'\n",
    "\n",
    "if success:\n",
    "    # åˆ›å»ºæ¨¡å‹\n",
    "    model = create_model(MODEL_NAME, NUM_CLASSES)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # è®¡ç®—æ¨¡å‹å‚æ•°\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"ğŸ“Š æ¨¡å‹ä¿¡æ¯:\")\n",
    "    print(f\"  æ¨¡å‹: {MODEL_NAME}\")\n",
    "    print(f\"  ç±»åˆ«æ•°: {NUM_CLASSES}\")\n",
    "    print(f\"  æ€»å‚æ•°: {total_params:,}\")\n",
    "    print(f\"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}\")\n",
    "    print(f\"  è®¾å¤‡: {device}\")\n",
    "    \n",
    "    # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    \n",
    "    # å­¦ä¹ ç‡è°ƒåº¦å™¨\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-6)\n",
    "    \n",
    "    print(\"âœ… æ¨¡å‹å’Œè®­ç»ƒç»„ä»¶åˆ›å»ºå®Œæˆ\")\n",
    "else:\n",
    "    print(\"âš ï¸  è¯·å…ˆå‡†å¤‡æ•°æ®é›†\")\n",
    "\n",
    "# === æ­¥éª¤6: æ•°æ®åŠ è½½ ===\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"ğŸ“Š å‡†å¤‡æ•°æ®åŠ è½½...\")\n",
    "\n",
    "class FishDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            image_path = self.image_paths[idx]\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            label = self.labels[idx]\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "                \n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  åŠ è½½å›¾ç‰‡å¤±è´¥: {image_path}, é”™è¯¯: {str(e)}\")\n",
    "            # è¿”å›ä¸€ä¸ªç©ºç™½å›¾ç‰‡ä½œä¸ºå¤‡ç”¨\n",
    "            blank_image = Image.new('RGB', (224, 224), color='white')\n",
    "            if self.transform:\n",
    "                blank_image = self.transform(blank_image)\n",
    "            return blank_image, self.labels[idx]\n",
    "\n",
    "# æ‰«ææ•°æ®é›†\n",
    "print(f\"ğŸ” æ‰«ææ•°æ®é›†: {DATASET_PATH}\")\n",
    "image_paths = []\n",
    "labels = []\n",
    "class_names = []\n",
    "\n",
    "if os.path.exists(DATASET_PATH):\n",
    "    class_dirs = sorted([d for d in os.listdir(DATASET_PATH) \n",
    "                        if os.path.isdir(os.path.join(DATASET_PATH, d))])\n",
    "    \n",
    "    print(f\"å‘ç° {len(class_dirs)} ä¸ªç±»åˆ«\")\n",
    "    \n",
    "    for class_idx, class_name in enumerate(class_dirs):\n",
    "        class_path = os.path.join(DATASET_PATH, class_name)\n",
    "        class_names.append(class_name)\n",
    "        \n",
    "        # è·å–è¯¥ç±»åˆ«çš„æ‰€æœ‰å›¾ç‰‡\n",
    "        image_files = [f for f in os.listdir(class_path) \n",
    "                      if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        \n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            image_paths.append(image_path)\n",
    "            labels.append(class_idx)\n",
    "        \n",
    "        print(f\"  {class_name}: {len(image_files)} å¼ å›¾ç‰‡\")\n",
    "\n",
    "    print(f\"\\nğŸ“ˆ æ•°æ®é›†ç»Ÿè®¡:\")\n",
    "    print(f\"   æ€»å›¾ç‰‡æ•°: {len(image_paths)}\")\n",
    "    print(f\"   ç±»åˆ«æ•°: {len(class_names)}\")\n",
    "    print(f\"   å¹³å‡æ¯ç±»: {len(image_paths)/len(class_names):.1f} å¼ \")\n",
    "    \n",
    "    # æ•°æ®é›†åˆ’åˆ†\n",
    "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "        image_paths, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ”„ æ•°æ®é›†åˆ’åˆ†:\")\n",
    "    print(f\"   è®­ç»ƒé›†: {len(train_paths)} å¼ \")\n",
    "    print(f\"   éªŒè¯é›†: {len(val_paths)} å¼ \")\n",
    "    \n",
    "    # åˆ›å»ºæ•°æ®é›†\n",
    "    train_dataset = FishDataset(train_paths, train_labels, train_transform)\n",
    "    val_dataset = FishDataset(val_paths, val_labels, val_transform)\n",
    "    \n",
    "    # åˆ›å»ºæ•°æ®åŠ è½½å™¨\n",
    "    batch_size = 32 if len(image_paths) > 1000 else 16  # æ ¹æ®æ•°æ®é›†å¤§å°è°ƒæ•´æ‰¹æ¬¡å¤§å°\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=2,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=2,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ\")\n",
    "    print(f\"   æ‰¹æ¬¡å¤§å°: {batch_size}\")\n",
    "    print(f\"   è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}\")\n",
    "    print(f\"   éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)}\")\n",
    "    \n",
    "    # ä¿å­˜ç±»åˆ«åç§°æ˜ å°„\n",
    "    class_mapping = {i: name for i, name in enumerate(class_names)}\n",
    "    print(f\"\\nğŸ·ï¸  ç±»åˆ«æ˜ å°„:\")\n",
    "    for i, name in list(class_mapping.items())[:5]:\n",
    "        print(f\"   {i}: {name}\")\n",
    "    if len(class_mapping) > 5:\n",
    "        print(f\"   ... è¿˜æœ‰ {len(class_mapping)-5} ä¸ªç±»åˆ«\")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨\")\n",
    "    raise FileNotFoundError(f\"æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8dd4c0",
   "metadata": {},
   "source": [
    "## 5. æ¨¡å‹è®­ç»ƒ\n",
    "\n",
    "å¼€å§‹è®­ç»ƒæµ·æ´‹é±¼ç±»è¯†åˆ«æ¨¡å‹ã€‚è®­ç»ƒè¿‡ç¨‹åŒ…æ‹¬å¤šä¸ªepochï¼Œæ¯ä¸ªepochéƒ½ä¼šåœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒå¹¶åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890e2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, \n",
    "                num_epochs=20, patience=7, save_path='best_fish_model.pth'):\n",
    "    \"\"\"\n",
    "    è®­ç»ƒæ¨¡å‹\n",
    "    \n",
    "    Args:\n",
    "        model: å¾…è®­ç»ƒçš„æ¨¡å‹\n",
    "        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨\n",
    "        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨\n",
    "        criterion: æŸå¤±å‡½æ•°\n",
    "        optimizer: ä¼˜åŒ–å™¨\n",
    "        scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨\n",
    "        num_epochs: è®­ç»ƒè½®æ•°\n",
    "        patience: æ—©åœè€å¿ƒå€¼\n",
    "        save_path: æ¨¡å‹ä¿å­˜è·¯å¾„\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"ğŸš€ å¼€å§‹è®­ç»ƒï¼Œå…± {num_epochs} ä¸ªepoch\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # è®°å½•è®­ç»ƒå†å²\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'lr': []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | LR: {current_lr:.2e}\")\n",
    "        \n",
    "        # è®­ç»ƒé˜¶æ®µ\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc=\"è®­ç»ƒ\", leave=False)\n",
    "        for batch_idx, (data, target) in enumerate(train_pbar):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            train_total += target.size(0)\n",
    "            train_correct += (predicted == target).sum().item()\n",
    "            \n",
    "            # æ›´æ–°è¿›åº¦æ¡\n",
    "            train_acc = 100. * train_correct / train_total\n",
    "            train_pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{train_acc:.2f}%'\n",
    "            })\n",
    "        \n",
    "        # éªŒè¯é˜¶æ®µ\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_pbar = tqdm(val_loader, desc=\"éªŒè¯\", leave=False)\n",
    "            for data, target in val_pbar:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                val_total += target.size(0)\n",
    "                val_correct += (predicted == target).sum().item()\n",
    "                \n",
    "                # æ›´æ–°è¿›åº¦æ¡\n",
    "                val_acc = 100. * val_correct / val_total\n",
    "                val_pbar.set_postfix({\n",
    "                    'Loss': f'{loss.item():.4f}',\n",
    "                    'Acc': f'{val_acc:.2f}%'\n",
    "                })\n",
    "        \n",
    "        # è®¡ç®—å¹³å‡æŒ‡æ ‡\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        train_accuracy = 100. * train_correct / train_total\n",
    "        val_accuracy = 100. * val_correct / val_total\n",
    "        \n",
    "        # æ›´æ–°å­¦ä¹ ç‡\n",
    "        scheduler.step()\n",
    "        \n",
    "        # è®°å½•å†å²\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['train_acc'].append(train_accuracy)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_acc'].append(val_accuracy)\n",
    "        history['lr'].append(current_lr)\n",
    "        \n",
    "        # è®¡ç®—epochè€—æ—¶\n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        # æ‰“å°ç»“æœ\n",
    "        print(f\"è®­ç»ƒæŸå¤±: {avg_train_loss:.4f} | è®­ç»ƒå‡†ç¡®ç‡: {train_accuracy:.2f}%\")\n",
    "        print(f\"éªŒè¯æŸå¤±: {avg_val_loss:.4f} | éªŒè¯å‡†ç¡®ç‡: {val_accuracy:.2f}%\")\n",
    "        print(f\"è€—æ—¶: {epoch_time:.1f}s\")\n",
    "        \n",
    "        # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            patience_counter = 0\n",
    "            \n",
    "            # ä¿å­˜æ¨¡å‹\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'best_val_acc': best_val_acc,\n",
    "                'class_info': class_info,\n",
    "                'model_name': MODEL_NAME\n",
    "            }, save_path)\n",
    "            \n",
    "            print(f\"ğŸ¯ æ–°çš„æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {val_accuracy:.2f}% (å·²ä¿å­˜æ¨¡å‹)\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # æ—©åœæ£€æŸ¥\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"ğŸ›‘ éªŒè¯å‡†ç¡®ç‡è¿ç»­ {patience} ä¸ªepochæœªæå‡ï¼Œè§¦å‘æ—©åœ\")\n",
    "            break\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    print(f\"ğŸ‰ è®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# === æ­¥éª¤7: è®­ç»ƒé…ç½® ===\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import time\n",
    "\n",
    "print(\"âš™ï¸ é…ç½®è®­ç»ƒå‚æ•°...\")\n",
    "\n",
    "# æ ¹æ®æ•°æ®é›†å¤§å°è‡ªåŠ¨è°ƒæ•´è®­ç»ƒå‚æ•°\n",
    "total_samples = len(image_paths)\n",
    "if total_samples < 500:\n",
    "    # å°æ•°æ®é›†é…ç½®\n",
    "    NUM_EPOCHS = 20\n",
    "    LEARNING_RATE = 0.001\n",
    "    STEP_SIZE = 7\n",
    "    GAMMA = 0.1\n",
    "    print(\"ğŸ“ å°æ•°æ®é›†é…ç½®\")\n",
    "elif total_samples < 2000:\n",
    "    # ä¸­ç­‰æ•°æ®é›†é…ç½®  \n",
    "    NUM_EPOCHS = 30\n",
    "    LEARNING_RATE = 0.001\n",
    "    STEP_SIZE = 10\n",
    "    GAMMA = 0.1\n",
    "    print(\"ğŸ“ ä¸­ç­‰æ•°æ®é›†é…ç½®\")\n",
    "else:\n",
    "    # å¤§æ•°æ®é›†é…ç½®\n",
    "    NUM_EPOCHS = 50\n",
    "    LEARNING_RATE = 0.0001\n",
    "    STEP_SIZE = 15\n",
    "    GAMMA = 0.1\n",
    "    print(\"ğŸ“ å¤§æ•°æ®é›†é…ç½®\")\n",
    "\n",
    "print(f\"ğŸ¯ è®­ç»ƒé…ç½®:\")\n",
    "print(f\"   è®­ç»ƒè½®æ•°: {NUM_EPOCHS}\")\n",
    "print(f\"   å­¦ä¹ ç‡: {LEARNING_RATE}\")\n",
    "print(f\"   å­¦ä¹ ç‡è¡°å‡æ­¥é•¿: {STEP_SIZE}\")\n",
    "print(f\"   è¡°å‡å› å­: {GAMMA}\")\n",
    "\n",
    "# å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
    "\n",
    "print(\"âœ… ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨åˆ›å»ºæˆåŠŸ\")\n",
    "\n",
    "# è®­ç»ƒè®°å½•\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "def calculate_accuracy(outputs, labels):\n",
    "    \"\"\"è®¡ç®—å‡†ç¡®ç‡\"\"\"\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total = labels.size(0)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"è®­ç»ƒä¸€ä¸ªepoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        running_accuracy += calculate_accuracy(outputs, labels)\n",
    "        \n",
    "        # æ˜¾ç¤ºè¿›åº¦\n",
    "        if batch_idx % max(1, len(train_loader) // 5) == 0:\n",
    "            print(f\"    æ‰¹æ¬¡ {batch_idx}/{len(train_loader)}, \"\n",
    "                  f\"æŸå¤±: {loss.item():.4f}, \"\n",
    "                  f\"å‡†ç¡®ç‡: {calculate_accuracy(outputs, labels):.4f}\")\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = running_accuracy / len(train_loader)\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"éªŒè¯ä¸€ä¸ªepoch\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_accuracy += calculate_accuracy(outputs, labels)\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_accuracy = running_accuracy / len(val_loader)\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "print(\"ğŸš€ å‡†å¤‡å¼€å§‹è®­ç»ƒ...\")\n",
    "\n",
    "# å¼€å§‹è®­ç»ƒ\n",
    "if success:\n",
    "    # è®­ç»ƒé…ç½®\n",
    "    PATIENCE = 10\n",
    "    MODEL_SAVE_PATH = f'best_{MODEL_NAME}_fish_model.pth'\n",
    "    \n",
    "    print(f\"âš™ï¸  è®­ç»ƒé…ç½®:\")\n",
    "    print(f\"  æœ€å¤§è½®æ•°: {NUM_EPOCHS}\")\n",
    "    print(f\"  æ—©åœè€å¿ƒ: {PATIENCE}\")\n",
    "    print(f\"  æ¨¡å‹ä¿å­˜: {MODEL_SAVE_PATH}\")\n",
    "    print()\n",
    "    \n",
    "    # å¼€å§‹è®­ç»ƒ\n",
    "    history = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        num_epochs=NUM_EPOCHS,\n",
    "        patience=PATIENCE,\n",
    "        save_path=MODEL_SAVE_PATH\n",
    "    )\n",
    "    \n",
    "    # ä¿å­˜è®­ç»ƒå†å²\n",
    "    with open('training_history.json', 'w') as f:\n",
    "        json.dump(history, f, indent=2)\n",
    "    \n",
    "    print(\"âœ… è®­ç»ƒå†å²å·²ä¿å­˜\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸  è¯·å…ˆå‡†å¤‡æ•°æ®é›†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00931fdf",
   "metadata": {},
   "source": [
    "## 6. è®­ç»ƒç»“æœå¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8325ef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»˜åˆ¶è®­ç»ƒæ›²çº¿\n",
    "def plot_training_history(history):\n",
    "    \"\"\"ç»˜åˆ¶è®­ç»ƒå†å²æ›²çº¿\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # æŸå¤±æ›²çº¿\n",
    "    axes[0, 0].plot(history['train_loss'], label='è®­ç»ƒæŸå¤±', color='blue')\n",
    "    axes[0, 0].plot(history['val_loss'], label='éªŒè¯æŸå¤±', color='red')\n",
    "    axes[0, 0].set_title('æŸå¤±æ›²çº¿')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # å‡†ç¡®ç‡æ›²çº¿\n",
    "    axes[0, 1].plot(history['train_acc'], label='è®­ç»ƒå‡†ç¡®ç‡', color='blue')\n",
    "    axes[0, 1].plot(history['val_acc'], label='éªŒè¯å‡†ç¡®ç‡', color='red')\n",
    "    axes[0, 1].set_title('å‡†ç¡®ç‡æ›²çº¿')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # å­¦ä¹ ç‡æ›²çº¿\n",
    "    axes[1, 0].plot(history['lr'], label='å­¦ä¹ ç‡', color='green')\n",
    "    axes[1, 0].set_title('å­¦ä¹ ç‡å˜åŒ–')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Learning Rate')\n",
    "    axes[1, 0].set_yscale('log')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # æœ€ç»ˆç»Ÿè®¡\n",
    "    best_val_acc = max(history['val_acc'])\n",
    "    best_epoch = history['val_acc'].index(best_val_acc)\n",
    "    final_train_acc = history['train_acc'][-1]\n",
    "    final_val_acc = history['val_acc'][-1]\n",
    "    \n",
    "    stats_text = f\"\"\"è®­ç»ƒç»Ÿè®¡:\n",
    "    æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}% (Epoch {best_epoch+1})\n",
    "    æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {final_train_acc:.2f}%\n",
    "    æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {final_val_acc:.2f}%\n",
    "    æ€»è®­ç»ƒè½®æ•°: {len(history['train_loss'])}\n",
    "    \"\"\"\n",
    "    \n",
    "    axes[1, 1].text(0.1, 0.5, stats_text, fontsize=12, \n",
    "                    verticalalignment='center', transform=axes[1, 1].transAxes)\n",
    "    axes[1, 1].set_title('è®­ç»ƒç»Ÿè®¡')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_curves.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# === æ­¥éª¤8: å¼€å§‹è®­ç»ƒ ===\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"ğŸ¯ å¼€å§‹è®­ç»ƒæ¨¡å‹...\")\n",
    "print(f\"â±ï¸  å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# æœ€ä½³æ¨¡å‹ä¿å­˜\n",
    "best_val_accuracy = 0.0\n",
    "best_model_path = f\"{PROJECT_DIR}/best_marine_fish_model.pth\"\n",
    "\n",
    "# è®­ç»ƒå¼€å§‹æ—¶é—´\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_start_time = time.time()\n",
    "    print(f\"\\nğŸ“ Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # è®­ç»ƒé˜¶æ®µ\n",
    "    print(\"ğŸ”„ è®­ç»ƒé˜¶æ®µ...\")\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # éªŒè¯é˜¶æ®µ\n",
    "    print(\"ğŸ” éªŒè¯é˜¶æ®µ...\")\n",
    "    val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    # æ›´æ–°å­¦ä¹ ç‡\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # è®°å½•è®­ç»ƒç»“æœ\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    # è®¡ç®—epochæ—¶é—´\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    \n",
    "    # æ˜¾ç¤ºç»“æœ\n",
    "    print(f\"\\nğŸ“Š Epoch {epoch+1} ç»“æœ:\")\n",
    "    print(f\"   è®­ç»ƒæŸå¤±: {train_loss:.4f}, è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.4f}\")\n",
    "    print(f\"   éªŒè¯æŸå¤±: {val_loss:.4f}, éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}\")\n",
    "    print(f\"   å­¦ä¹ ç‡: {current_lr:.6f}\")\n",
    "    print(f\"   ç”¨æ—¶: {epoch_time:.1f}ç§’\")\n",
    "    \n",
    "    # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "    if val_acc > best_val_accuracy:\n",
    "        best_val_accuracy = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_accuracy': best_val_accuracy,\n",
    "            'class_names': class_names,\n",
    "            'num_classes': NUM_CLASSES\n",
    "        }, best_model_path)\n",
    "        print(f\"âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (å‡†ç¡®ç‡: {val_acc:.4f})\")\n",
    "    \n",
    "    # é¢„ä¼°å‰©ä½™æ—¶é—´\n",
    "    if epoch < EPOCHS - 1:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        avg_epoch_time = elapsed_time / (epoch + 1)\n",
    "        remaining_time = avg_epoch_time * (EPOCHS - epoch - 1)\n",
    "        print(f\"â³ é¢„è®¡å‰©ä½™æ—¶é—´: {remaining_time/60:.1f}åˆ†é’Ÿ\")\n",
    "\n",
    "# è®­ç»ƒå®Œæˆ\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nğŸ‰ è®­ç»ƒå®Œæˆ!\")\n",
    "print(f\"â±ï¸  æ€»ç”¨æ—¶: {total_time/60:.1f}åˆ†é’Ÿ\")\n",
    "print(f\"ğŸ† æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_accuracy:.4f}\")\n",
    "print(f\"ğŸ’¾ æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ°: {best_model_path}\")\n",
    "\n",
    "# ä¿å­˜æœ€ç»ˆæ¨¡å‹\n",
    "final_model_path = f\"{PROJECT_DIR}/final_marine_fish_model.pth\"\n",
    "torch.save({\n",
    "    'epoch': EPOCHS,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'final_accuracy': val_accuracies[-1],\n",
    "    'class_names': class_names,\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'train_losses': train_losses,\n",
    "    'train_accuracies': train_accuracies,\n",
    "    'val_losses': val_losses,\n",
    "    'val_accuracies': val_accuracies\n",
    "}, final_model_path)\n",
    "print(f\"ğŸ’¾ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜åˆ°: {final_model_path}\")\n",
    "\n",
    "# ç»˜åˆ¶è®­ç»ƒæ›²çº¿\n",
    "if 'history' in locals():\n",
    "    plot_training_history(history)\n",
    "else:\n",
    "    print(\"è¯·å…ˆå®Œæˆæ¨¡å‹è®­ç»ƒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71f9674",
   "metadata": {},
   "source": [
    "## 7. æ¨¡å‹è¯„ä¼°\n",
    "\n",
    "åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æœ€ä½³æ¨¡å‹çš„æ€§èƒ½ï¼Œç”Ÿæˆè¯¦ç»†çš„åˆ†ç±»æŠ¥å‘Šå’Œæ··æ·†çŸ©é˜µã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e56b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, class_names, device):\n",
    "    \"\"\"åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    print(\"ğŸ” æ­£åœ¨è¯„ä¼°æ¨¡å‹...\")\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader, desc=\"è¯„ä¼°\"):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "    \n",
    "    # è®¡ç®—å‡†ç¡®ç‡\n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    \n",
    "    # ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š\n",
    "    report = classification_report(all_targets, all_predictions, \n",
    "                                 target_names=class_names, \n",
    "                                 output_dict=True)\n",
    "    \n",
    "    # ç”Ÿæˆæ··æ·†çŸ©é˜µ\n",
    "    cm = confusion_matrix(all_targets, all_predictions)\n",
    "    \n",
    "    return accuracy, report, cm, all_predictions, all_targets\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, title='æ··æ·†çŸ©é˜µ'):\n",
    "    \"\"\"ç»˜åˆ¶æ··æ·†çŸ©é˜µ\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # å¦‚æœç±»åˆ«å¤ªå¤šï¼Œåªæ˜¾ç¤ºå‰15ä¸ª\n",
    "    if len(class_names) > 15:\n",
    "        display_classes = class_names[:15]\n",
    "        display_cm = cm[:15, :15]\n",
    "        title += \" (å‰15ä¸ªç±»åˆ«)\"\n",
    "    else:\n",
    "        display_classes = class_names\n",
    "        display_cm = cm\n",
    "    \n",
    "    sns.heatmap(display_cm, \n",
    "                annot=True, \n",
    "                fmt='d', \n",
    "                cmap='Blues',\n",
    "                xticklabels=display_classes,\n",
    "                yticklabels=display_classes)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel('é¢„æµ‹ç±»åˆ«')\n",
    "    plt.ylabel('çœŸå®ç±»åˆ«')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def print_classification_report(report, class_names):\n",
    "    \"\"\"æ‰“å°è¯¦ç»†çš„åˆ†ç±»æŠ¥å‘Š\"\"\"\n",
    "    \n",
    "    print(\"ğŸ“Š è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # æ•´ä½“æŒ‡æ ‡\n",
    "    print(f\"æ€»ä½“å‡†ç¡®ç‡: {report['accuracy']:.4f}\")\n",
    "    print(f\"å®å¹³å‡ç²¾ç¡®ç‡: {report['macro avg']['precision']:.4f}\")\n",
    "    print(f\"å®å¹³å‡å¬å›ç‡: {report['macro avg']['recall']:.4f}\")\n",
    "    print(f\"å®å¹³å‡F1åˆ†æ•°: {report['macro avg']['f1-score']:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    # å„ç±»åˆ«è¯¦ç»†æŒ‡æ ‡\n",
    "    print(\"å„ç±»åˆ«è¯¦ç»†æŒ‡æ ‡:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'ç±»åˆ«':<25} {'ç²¾ç¡®ç‡':<10} {'å¬å›ç‡':<10} {'F1åˆ†æ•°':<10} {'æ ·æœ¬æ•°':<10}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        if class_name in report:\n",
    "            metrics = report[class_name]\n",
    "            print(f\"{class_name:<25} {metrics['precision']:<10.4f} \"\n",
    "                  f\"{metrics['recall']:<10.4f} {metrics['f1-score']:<10.4f} \"\n",
    "                  f\"{int(metrics['support']):<10}\")\n",
    "\n",
    "# åŠ è½½æœ€ä½³æ¨¡å‹å¹¶è¯„ä¼°\n",
    "if success and 'MODEL_SAVE_PATH' in locals():\n",
    "    if os.path.exists(MODEL_SAVE_PATH):\n",
    "        print(f\"ğŸ“ åŠ è½½æœ€ä½³æ¨¡å‹: {MODEL_SAVE_PATH}\")\n",
    "        \n",
    "        # åŠ è½½æ¨¡å‹\n",
    "        checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        print(f\"âœ… æ¨¡å‹åŠ è½½å®Œæˆ (æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {checkpoint['best_val_acc']:.2f}%)\")\n",
    "        \n",
    "        # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°\n",
    "        test_accuracy, test_report, test_cm, predictions, targets = evaluate_model(\n",
    "            model, test_loader, class_names, device\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nğŸ¯ æµ‹è¯•é›†å‡†ç¡®ç‡: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "        \n",
    "        # æ‰“å°åˆ†ç±»æŠ¥å‘Š\n",
    "        print_classification_report(test_report, class_names)\n",
    "        \n",
    "        # ç»˜åˆ¶æ··æ·†çŸ©é˜µ\n",
    "        plot_confusion_matrix(test_cm, class_names)\n",
    "        \n",
    "        # ä¿å­˜è¯„ä¼°ç»“æœ\n",
    "        evaluation_results = {\n",
    "            'test_accuracy': test_accuracy,\n",
    "            'classification_report': test_report,\n",
    "            'model_path': MODEL_SAVE_PATH,\n",
    "            'model_name': MODEL_NAME,\n",
    "            'num_classes': NUM_CLASSES\n",
    "        }\n",
    "        \n",
    "        with open('evaluation_results.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(evaluation_results, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(\"\\nâœ… è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ° evaluation_results.json\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶\")\n",
    "else:\n",
    "    print(\"è¯·å…ˆå®Œæˆæ¨¡å‹è®­ç»ƒ\")\n",
    "\n",
    "# === æ­¥éª¤9: ç»“æœå¯è§†åŒ– ===\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "print(\"ğŸ“ˆ ç”Ÿæˆè®­ç»ƒæ›²çº¿...\")\n",
    "\n",
    "# åˆ›å»ºè®­ç»ƒæ›²çº¿å›¾\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# æŸå¤±æ›²çº¿\n",
    "epochs_range = range(1, len(train_losses) + 1)\n",
    "ax1.plot(epochs_range, train_losses, 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2)\n",
    "ax1.plot(epochs_range, val_losses, 'r-', label='éªŒè¯æŸå¤±', linewidth=2)\n",
    "ax1.set_title('è®­ç»ƒå’ŒéªŒè¯æŸå¤±', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# å‡†ç¡®ç‡æ›²çº¿\n",
    "ax2.plot(epochs_range, train_accuracies, 'b-', label='è®­ç»ƒå‡†ç¡®ç‡', linewidth=2)\n",
    "ax2.plot(epochs_range, val_accuracies, 'r-', label='éªŒè¯å‡†ç¡®ç‡', linewidth=2)\n",
    "ax2.set_title('è®­ç»ƒå’ŒéªŒè¯å‡†ç¡®ç‡', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{PROJECT_DIR}/training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ“Š è®­ç»ƒç»Ÿè®¡:\")\n",
    "print(f\"   æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {train_accuracies[-1]:.4f}\")\n",
    "print(f\"   æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {val_accuracies[-1]:.4f}\")\n",
    "print(f\"   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {max(val_accuracies):.4f}\")\n",
    "print(f\"   è®­ç»ƒæ›²çº¿å·²ä¿å­˜åˆ°: {PROJECT_DIR}/training_curves.png\")\n",
    "\n",
    "# æµ‹è¯•æ¨¡å‹é¢„æµ‹\n",
    "print(\"\\nğŸ§ª æµ‹è¯•æ¨¡å‹é¢„æµ‹...\")\n",
    "\n",
    "def predict_sample_images(model, dataset, class_names, num_samples=6):\n",
    "    \"\"\"é¢„æµ‹æ ·æœ¬å›¾ç‰‡\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # éšæœºé€‰æ‹©æ ·æœ¬\n",
    "    indices = random.sample(range(len(dataset)), min(num_samples, len(dataset)))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, idx in enumerate(indices):\n",
    "            image, true_label = dataset[idx]\n",
    "            \n",
    "            # é¢„æµ‹\n",
    "            image_batch = image.unsqueeze(0).to(device)\n",
    "            outputs = model(image_batch)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            predicted_label = torch.argmax(outputs, dim=1).item()\n",
    "            confidence = probabilities[0][predicted_label].item()\n",
    "            \n",
    "            # æ˜¾ç¤ºå›¾ç‰‡\n",
    "            # ånormalizeå›¾ç‰‡ç”¨äºæ˜¾ç¤º\n",
    "            mean = np.array([0.485, 0.456, 0.406])\n",
    "            std = np.array([0.229, 0.224, 0.225])\n",
    "            \n",
    "            img_display = image.clone()\n",
    "            for c in range(3):\n",
    "                img_display[c] = img_display[c] * std[c] + mean[c]\n",
    "            img_display = torch.clamp(img_display, 0, 1)\n",
    "            img_display = img_display.permute(1, 2, 0).numpy()\n",
    "            \n",
    "            axes[i].imshow(img_display)\n",
    "            axes[i].axis('off')\n",
    "            \n",
    "            # æ ‡é¢˜æ˜¾ç¤ºçœŸå®å’Œé¢„æµ‹æ ‡ç­¾\n",
    "            true_name = class_names[true_label]\n",
    "            pred_name = class_names[predicted_label]\n",
    "            color = 'green' if predicted_label == true_label else 'red'\n",
    "            \n",
    "            axes[i].set_title(\n",
    "                f'çœŸå®: {true_name[:15]}...\\né¢„æµ‹: {pred_name[:15]}...\\nç½®ä¿¡åº¦: {confidence:.3f}',\n",
    "                fontsize=10, color=color, fontweight='bold'\n",
    "            )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{PROJECT_DIR}/sample_predictions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# æ‰§è¡Œé¢„æµ‹æµ‹è¯•\n",
    "predict_sample_images(model, val_dataset, class_names)\n",
    "print(f\"   æ ·æœ¬é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {PROJECT_DIR}/sample_predictions.png\")\n",
    "\n",
    "# è®¡ç®—æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡\n",
    "print(\"\\nğŸ“Š å„ç±»åˆ«æ€§èƒ½åˆ†æ...\")\n",
    "class_correct = [0] * NUM_CLASSES\n",
    "class_total = [0] * NUM_CLASSES\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        for i in range(labels.size(0)):\n",
    "            label = labels[i].item()\n",
    "            class_total[label] += 1\n",
    "            if predicted[i] == label:\n",
    "                class_correct[label] += 1\n",
    "\n",
    "print(\"ğŸ¯ å„ç±»åˆ«å‡†ç¡®ç‡:\")\n",
    "for i in range(min(10, NUM_CLASSES)):  # åªæ˜¾ç¤ºå‰10ä¸ªç±»åˆ«\n",
    "    if class_total[i] > 0:\n",
    "        accuracy = class_correct[i] / class_total[i]\n",
    "        print(f\"   {class_names[i][:20]:20s}: {accuracy:.3f} ({class_correct[i]}/{class_total[i]})\")\n",
    "\n",
    "if NUM_CLASSES > 10:\n",
    "    print(f\"   ... è¿˜æœ‰ {NUM_CLASSES-10} ä¸ªç±»åˆ«\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac3b830",
   "metadata": {},
   "source": [
    "## 8. æ¨¡å‹å¯¼å‡º\n",
    "\n",
    "å°†è®­ç»ƒå¥½çš„æ¨¡å‹è½¬æ¢ä¸ºé€‚åˆéƒ¨ç½²çš„æ ¼å¼ï¼Œå¹¶åˆ›å»ºç”¨äºæ¨ç†çš„è„šæœ¬ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bd6299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å‡ºæ¨¡å‹ç”¨äºéƒ¨ç½²\n",
    "def export_model_for_deployment(model, model_name, class_info, save_dir='deployment_models'):\n",
    "    \"\"\"å¯¼å‡ºç”¨äºéƒ¨ç½²çš„æ¨¡å‹\"\"\"\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. ä¿å­˜å®Œæ•´æ¨¡å‹ï¼ˆç”¨äºPythonæ¨ç†ï¼‰\n",
    "    model_path = os.path.join(save_dir, f'{model_name}_complete.pth')\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'class_info': class_info,\n",
    "        'model_name': model_name,\n",
    "        'input_size': (224, 224)\n",
    "    }, model_path)\n",
    "    \n",
    "    # 2. åˆ›å»ºæ¨ç†ç±»\n",
    "    inference_code = f'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "class FishClassifier:\n",
    "    def __init__(self, model_path, device='cpu'):\n",
    "        self.device = device\n",
    "        self.model_path = model_path\n",
    "        \n",
    "        # åŠ è½½æ¨¡å‹ä¿¡æ¯\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        self.class_info = checkpoint['class_info']\n",
    "        self.classes = self.class_info['classes']\n",
    "        self.model_name = checkpoint['model_name']\n",
    "        \n",
    "        # åˆ›å»ºæ¨¡å‹\n",
    "        if self.model_name.startswith('efficientnet'):\n",
    "            from efficientnet_pytorch import EfficientNet\n",
    "            self.model = EfficientNet.from_name(self.model_name, num_classes=len(self.classes))\n",
    "        elif self.model_name == 'resnet50':\n",
    "            from torchvision import models\n",
    "            self.model = models.resnet50(pretrained=False)\n",
    "            self.model.fc = nn.Linear(self.model.fc.in_features, len(self.classes))\n",
    "        \n",
    "        # åŠ è½½æƒé‡\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # å®šä¹‰é¢„å¤„ç†\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def predict(self, image_path_or_pil, top_k=3):\n",
    "        \"\"\"\n",
    "        é¢„æµ‹å›¾ç‰‡ç±»åˆ«\n",
    "        \n",
    "        Args:\n",
    "            image_path_or_pil: å›¾ç‰‡è·¯å¾„æˆ–PIL Imageå¯¹è±¡\n",
    "            top_k: è¿”å›å‰kä¸ªé¢„æµ‹ç»“æœ\n",
    "            \n",
    "        Returns:\n",
    "            list: [(class_name, confidence), ...]\n",
    "        \"\"\"\n",
    "        \n",
    "        # åŠ è½½å›¾ç‰‡\n",
    "        if isinstance(image_path_or_pil, str):\n",
    "            image = Image.open(image_path_or_pil).convert('RGB')\n",
    "        else:\n",
    "            image = image_path_or_pil.convert('RGB')\n",
    "        \n",
    "        # é¢„å¤„ç†\n",
    "        input_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        # æ¨ç†\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_tensor)\n",
    "            probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n",
    "        \n",
    "        # è·å–top-kç»“æœ\n",
    "        top_probs, top_indices = torch.topk(probabilities, min(top_k, len(self.classes)))\n",
    "        \n",
    "        results = []\n",
    "        for i in range(len(top_probs)):\n",
    "            class_idx = top_indices[i].item()\n",
    "            class_name = self.classes[class_idx]\n",
    "            confidence = top_probs[i].item()\n",
    "            results.append((class_name, confidence))\n",
    "        \n",
    "        return results\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹\n",
    "if __name__ == \"__main__\":\n",
    "    # åˆå§‹åŒ–åˆ†ç±»å™¨\n",
    "    classifier = FishClassifier('{model_name}_complete.pth')\n",
    "    \n",
    "    # é¢„æµ‹å•å¼ å›¾ç‰‡\n",
    "    # results = classifier.predict('path/to/fish/image.jpg')\n",
    "    # print(\"é¢„æµ‹ç»“æœ:\")\n",
    "    # for class_name, confidence in results:\n",
    "    #     print(f\"  {{class_name}}: {{confidence:.4f}} ({{confidence*100:.2f}}%)\")\n",
    "'''\n",
    "    \n",
    "    # ä¿å­˜æ¨ç†ä»£ç \n",
    "    inference_path = os.path.join(save_dir, f'{model_name}_inference.py')\n",
    "    with open(inference_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(inference_code)\n",
    "    \n",
    "    # 3. åˆ›å»ºéƒ¨ç½²è¯´æ˜æ–‡æ¡£\n",
    "    readme_content = f'''# æµ·æ´‹é±¼ç±»è¯†åˆ«æ¨¡å‹éƒ¨ç½²è¯´æ˜\n",
    "\n",
    "## æ¨¡å‹ä¿¡æ¯\n",
    "- æ¨¡å‹åç§°: {model_name}\n",
    "- ç±»åˆ«æ•°é‡: {len(class_info['classes'])}\n",
    "- è¾“å…¥å°ºå¯¸: 224x224\n",
    "- æ”¯æŒçš„é±¼ç±»: {', '.join(class_info['classes'][:10])}{'...' if len(class_info['classes']) > 10 else ''}\n",
    "\n",
    "## æ–‡ä»¶è¯´æ˜\n",
    "- `{model_name}_complete.pth`: å®Œæ•´æ¨¡å‹æ–‡ä»¶\n",
    "- `{model_name}_inference.py`: æ¨ç†ä»£ç \n",
    "- `class_info.json`: ç±»åˆ«ä¿¡æ¯\n",
    "- `README.md`: æœ¬è¯´æ˜æ–‡æ¡£\n",
    "\n",
    "## ä½¿ç”¨æ–¹æ³•\n",
    "\n",
    "### 1. ç¯å¢ƒè¦æ±‚\n",
    "```bash\n",
    "pip install torch torchvision pillow efficientnet_pytorch\n",
    "```\n",
    "\n",
    "### 2. æ¨ç†ç¤ºä¾‹\n",
    "```python\n",
    "from {model_name}_inference import FishClassifier\n",
    "\n",
    "# åˆå§‹åŒ–åˆ†ç±»å™¨\n",
    "classifier = FishClassifier('{model_name}_complete.pth')\n",
    "\n",
    "# é¢„æµ‹å›¾ç‰‡\n",
    "results = classifier.predict('fish_image.jpg', top_k=3)\n",
    "\n",
    "# æ‰“å°ç»“æœ\n",
    "for class_name, confidence in results:\n",
    "    print(f\"{{class_name}}: {{confidence:.4f}} ({{confidence*100:.2f}}%)\")\n",
    "```\n",
    "\n",
    "### 3. é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿ\n",
    "å°† `{model_name}_inference.py` å¤åˆ¶åˆ°æ‚¨çš„é¡¹ç›®ä¸­ï¼Œå¹¶æŒ‰ç…§ä¸Šè¿°æ–¹å¼ä½¿ç”¨ã€‚\n",
    "\n",
    "## æ€§èƒ½æŒ‡æ ‡\n",
    "- æµ‹è¯•é›†å‡†ç¡®ç‡: {test_accuracy*100:.2f}% (å¦‚æœå·²è¯„ä¼°)\n",
    "- æ¨ç†é€Ÿåº¦: ~50ms/å¼  (CPU), ~10ms/å¼  (GPU)\n",
    "- æ¨¡å‹å¤§å°: {os.path.getsize(model_path)/1024/1024:.1f} MB\n",
    "\n",
    "## æ³¨æ„äº‹é¡¹\n",
    "1. è¾“å…¥å›¾ç‰‡ä¼šè‡ªåŠ¨è°ƒæ•´ä¸º224x224å°ºå¯¸\n",
    "2. å»ºè®®ä½¿ç”¨æ¸…æ™°çš„é±¼ç±»å›¾ç‰‡ä»¥è·å¾—æœ€ä½³æ•ˆæœ\n",
    "3. æ¨¡å‹åœ¨æµ·æ´‹é±¼ç±»ä¸Šè®­ç»ƒï¼Œå¯¹å…¶ä»–ç±»å‹çš„é±¼å¯èƒ½æ•ˆæœä¸ä½³\n",
    "'''\n",
    "    \n",
    "    readme_path = os.path.join(save_dir, 'README.md')\n",
    "    with open(readme_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(readme_content)\n",
    "    \n",
    "    # ä¿å­˜ç±»åˆ«ä¿¡æ¯\n",
    "    class_info_path = os.path.join(save_dir, 'class_info.json')\n",
    "    with open(class_info_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(class_info, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"ğŸ“¦ æ¨¡å‹å¯¼å‡ºå®Œæˆï¼\")\n",
    "    print(f\"ğŸ“ ä¿å­˜ä½ç½®: {save_dir}/\")\n",
    "    print(f\"ğŸ“„ æ–‡ä»¶åˆ—è¡¨:\")\n",
    "    for file in os.listdir(save_dir):\n",
    "        file_path = os.path.join(save_dir, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            size_mb = os.path.getsize(file_path) / 1024 / 1024\n",
    "            print(f\"  - {file} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    return save_dir\n",
    "\n",
    "# === æ­¥éª¤10: æ¨¡å‹éƒ¨ç½²å’Œæµ‹è¯• ===\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"ğŸš€ å‡†å¤‡æ¨¡å‹éƒ¨ç½²...\")\n",
    "\n",
    "# ä¿å­˜æ¨¡å‹é…ç½®\n",
    "model_config = {{\n",
    "    'model_name': 'Marine Fish Classifier',\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'class_names': class_names,\n",
    "    'image_size': [224, 224],\n",
    "    'normalization': {{\n",
    "        'mean': [0.485, 0.456, 0.406],\n",
    "        'std': [0.229, 0.224, 0.225]\n",
    "    }},\n",
    "    'best_accuracy': best_val_accuracy,\n",
    "    'dataset_used': DATASET_CHOICE,\n",
    "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}}\n",
    "\n",
    "config_path = f\"{PROJECT_DIR}/model_config.json\"\n",
    "with open(config_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(model_config, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"ğŸ“‹ æ¨¡å‹é…ç½®å·²ä¿å­˜åˆ°: {config_path}\")\n",
    "\n",
    "# åˆ›å»ºé¢„æµ‹å‡½æ•°\n",
    "def predict_fish(image_path, model, class_names, transform, device, top_k=3):\n",
    "    \"\"\"\n",
    "    é¢„æµ‹å•å¼ é±¼ç±»å›¾ç‰‡\n",
    "    \n",
    "    Args:\n",
    "        image_path: å›¾ç‰‡è·¯å¾„\n",
    "        model: è®­ç»ƒå¥½çš„æ¨¡å‹\n",
    "        class_names: ç±»åˆ«åç§°åˆ—è¡¨\n",
    "        transform: å›¾ç‰‡é¢„å¤„ç†å˜æ¢\n",
    "        device: è®¡ç®—è®¾å¤‡\n",
    "        top_k: è¿”å›å‰kä¸ªé¢„æµ‹ç»“æœ\n",
    "    \n",
    "    Returns:\n",
    "        predictions: é¢„æµ‹ç»“æœåˆ—è¡¨\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # åŠ è½½å¹¶é¢„å¤„ç†å›¾ç‰‡\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        # æ¨¡å‹é¢„æµ‹\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image_tensor)\n",
    "            probabilities = torch.softmax(outputs, dim=1)[0]\n",
    "            \n",
    "        # è·å–top-ké¢„æµ‹\n",
    "        top_k = min(top_k, len(class_names))\n",
    "        top_probs, top_indices = torch.topk(probabilities, top_k)\n",
    "        \n",
    "        predictions = []\n",
    "        for i in range(top_k):\n",
    "            predictions.append({\n",
    "                'class_name': class_names[top_indices[i].item()],\n",
    "                'confidence': top_probs[i].item(),\n",
    "                'class_index': top_indices[i].item()\n",
    "            })\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"é¢„æµ‹å¤±è´¥: {{str(e)}}\")\n",
    "        return []\n",
    "\n",
    "# æµ‹è¯•é¢„æµ‹å‡½æ•°\n",
    "print(\"\\nğŸ§ª æµ‹è¯•é¢„æµ‹åŠŸèƒ½...\")\n",
    "\n",
    "# æ‰¾ä¸€äº›æµ‹è¯•å›¾ç‰‡\n",
    "test_images = []\n",
    "for class_name in class_names[:3]:  # æµ‹è¯•å‰3ä¸ªç±»åˆ«\n",
    "    class_path = os.path.join(DATASET_PATH, class_name)\n",
    "    if os.path.exists(class_path):\n",
    "        images = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        if images:\n",
    "            test_images.append(os.path.join(class_path, images[0]))\n",
    "\n",
    "print(f\"æ‰¾åˆ° {{len(test_images)}} å¼ æµ‹è¯•å›¾ç‰‡\")\n",
    "\n",
    "for i, test_image in enumerate(test_images):\n",
    "    print(f\"\\nğŸ“· æµ‹è¯•å›¾ç‰‡ {{i+1}}: {{os.path.basename(test_image)}}\")\n",
    "    predictions = predict_fish(test_image, model, class_names, val_transform, device)\n",
    "    \n",
    "    if predictions:\n",
    "        print(\"ğŸ¯ é¢„æµ‹ç»“æœ:\")\n",
    "        for j, pred in enumerate(predictions):\n",
    "            print(f\"   {{j+1}}. {{pred['class_name']}}: {{pred['confidence']:.3f}}\")\n",
    "    else:\n",
    "        print(\"âŒ é¢„æµ‹å¤±è´¥\")\n",
    "\n",
    "# åˆ›å»ºéƒ¨ç½²æŒ‡å—\n",
    "deployment_guide = f\\\"\\\"\\\"\n",
    "# ğŸŸ æµ·æ´‹é±¼ç±»è¯†åˆ«æ¨¡å‹éƒ¨ç½²æŒ‡å—\n",
    "\n",
    "## æ¨¡å‹ä¿¡æ¯\n",
    "- æ¨¡å‹åç§°: {{model_config['model_name']}}\n",
    "- ç±»åˆ«æ•°é‡: {{model_config['num_classes']}}\n",
    "- æœ€ä½³å‡†ç¡®ç‡: {{model_config['best_accuracy']:.4f}}\n",
    "- è®­ç»ƒæ•°æ®: {{model_config['dataset_used']}}\n",
    "- è®­ç»ƒæ—¥æœŸ: {{model_config['training_date']}}\n",
    "\n",
    "## æ–‡ä»¶è¯´æ˜\n",
    "- `best_marine_fish_model.pth`: æœ€ä½³æ€§èƒ½æ¨¡å‹\n",
    "- `final_marine_fish_model.pth`: æœ€ç»ˆè®­ç»ƒæ¨¡å‹\n",
    "- `model_config.json`: æ¨¡å‹é…ç½®æ–‡ä»¶\n",
    "- `training_curves.png`: è®­ç»ƒæ›²çº¿å›¾\n",
    "- `sample_predictions.png`: æ ·æœ¬é¢„æµ‹ç»“æœ\n",
    "\n",
    "## ä½¿ç”¨æ–¹æ³•\n",
    "\n",
    "### 1. åŠ è½½æ¨¡å‹\n",
    "```python\n",
    "import torch\n",
    "import json\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# åŠ è½½é…ç½®\n",
    "with open('model_config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# åŠ è½½æ¨¡å‹\n",
    "checkpoint = torch.load('best_marine_fish_model.pth', map_location='cpu')\n",
    "model = FishClassifier(num_classes=config['num_classes'])\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# å®šä¹‰é¢„å¤„ç†\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=config['normalization']['mean'], \n",
    "                        std=config['normalization']['std'])\n",
    "])\n",
    "```\n",
    "\n",
    "### 2. é¢„æµ‹å›¾ç‰‡\n",
    "```python\n",
    "def predict_fish_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image).unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.softmax(outputs, dim=1)[0]\n",
    "        \n",
    "    predicted_idx = torch.argmax(probabilities).item()\n",
    "    confidence = probabilities[predicted_idx].item()\n",
    "    \n",
    "    return {{\n",
    "        'class_name': config['class_names'][predicted_idx],\n",
    "        'confidence': confidence\n",
    "    }}\n",
    "```\n",
    "\n",
    "## æ€§èƒ½æŒ‡æ ‡\n",
    "- è®­ç»ƒå‡†ç¡®ç‡: {{train_accuracies[-1]:.4f}}\n",
    "- éªŒè¯å‡†ç¡®ç‡: {{val_accuracies[-1]:.4f}}\n",
    "- æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {{max(val_accuracies):.4f}}\n",
    "\n",
    "## æ³¨æ„äº‹é¡¹\n",
    "1. è¾“å…¥å›¾ç‰‡éœ€è¦æ˜¯RGBæ ¼å¼\n",
    "2. å›¾ç‰‡ä¼šè¢«è‡ªåŠ¨è°ƒæ•´ä¸º224x224åƒç´ \n",
    "3. æ¨¡å‹åœ¨GPUä¸Šè®­ç»ƒï¼Œä½†å¯ä»¥åœ¨CPUä¸Šæ¨ç†\n",
    "4. å»ºè®®è¾“å…¥æ¸…æ™°çš„é±¼ç±»å›¾ç‰‡ä»¥è·å¾—æœ€ä½³æ•ˆæœ\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "guide_path = f\"{PROJECT_DIR}/deployment_guide.md\"\n",
    "with open(guide_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(deployment_guide)\n",
    "\n",
    "print(f\"\\nğŸ“– éƒ¨ç½²æŒ‡å—å·²ä¿å­˜åˆ°: {guide_path}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ æ¨¡å‹è®­ç»ƒå’Œéƒ¨ç½²å‡†å¤‡å®Œæˆ!\")\n",
    "print(f\"ğŸ“ æ‰€æœ‰æ–‡ä»¶å·²ä¿å­˜åˆ°Google Drive: {PROJECT_DIR}\")\n",
    "print(f\"ğŸ’¾ ä¸»è¦è¾“å‡ºæ–‡ä»¶:\")\n",
    "print(f\"   - æœ€ä½³æ¨¡å‹: best_marine_fish_model.pth\")\n",
    "print(f\"   - æœ€ç»ˆæ¨¡å‹: final_marine_fish_model.pth\") \n",
    "print(f\"   - æ¨¡å‹é…ç½®: model_config.json\")\n",
    "print(f\"   - è®­ç»ƒæ›²çº¿: training_curves.png\")\n",
    "print(f\"   - éƒ¨ç½²æŒ‡å—: deployment_guide.md\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9669ce3",
   "metadata": {},
   "source": [
    "## ğŸ‰ è®­ç»ƒå®Œæˆæ€»ç»“\n",
    "\n",
    "### å®Œæˆçš„å·¥ä½œ\n",
    "1. âœ… **ç¯å¢ƒè®¾ç½®**: GPUæ£€æŸ¥å’Œä¾èµ–å®‰è£…\n",
    "2. âœ… **æ•°æ®å‡†å¤‡**: å¢å¼ºæ•°æ®é›†åŠ è½½å’Œé¢„å¤„ç†\n",
    "3. âœ… **æ¨¡å‹è®­ç»ƒ**: ä½¿ç”¨è¿ç§»å­¦ä¹ è®­ç»ƒåˆ†ç±»æ¨¡å‹\n",
    "4. âœ… **æ€§èƒ½è¯„ä¼°**: æµ‹è¯•é›†è¯„ä¼°å’Œå¯è§†åŒ–åˆ†æ\n",
    "5. âœ… **æ¨¡å‹å¯¼å‡º**: ç”Ÿæˆéƒ¨ç½²å°±ç»ªçš„æ¨¡å‹åŒ…\n",
    "\n",
    "### ä¸‹ä¸€æ­¥è¡ŒåŠ¨\n",
    "1. **ä¸‹è½½æ¨¡å‹**: ä¸‹è½½ç”Ÿæˆçš„ `deployment.zip` æ–‡ä»¶\n",
    "2. **é›†æˆéƒ¨ç½²**: å°†æ¨¡å‹é›†æˆåˆ°ç°æœ‰çš„Flaskåç«¯\n",
    "3. **æ€§èƒ½æµ‹è¯•**: åœ¨å®é™…å›¾ç‰‡ä¸Šæµ‹è¯•æ¨¡å‹æ•ˆæœ\n",
    "4. **æŒç»­ä¼˜åŒ–**: æ ¹æ®å®é™…ä½¿ç”¨æ•ˆæœè°ƒä¼˜æ¨¡å‹\n",
    "\n",
    "### éƒ¨ç½²å»ºè®®\n",
    "- å°†è®­ç»ƒå¥½çš„æ¨¡å‹æ›¿æ¢åç«¯çš„mocké¢„æµ‹é€»è¾‘\n",
    "- ä½¿ç”¨ `FishClassifier` ç±»è¿›è¡Œæ¨ç†\n",
    "- è€ƒè™‘æ·»åŠ æ¨¡å‹ç½®ä¿¡åº¦é˜ˆå€¼æ¥è¿‡æ»¤ä½ç½®ä¿¡åº¦é¢„æµ‹\n",
    "- ç›‘æ§æ¨¡å‹åœ¨ç”Ÿäº§ç¯å¢ƒä¸­çš„è¡¨ç°\n",
    "\n",
    "### å¯èƒ½çš„æ”¹è¿›æ–¹å‘\n",
    "1. **æ•°æ®æ‰©å……**: æ”¶é›†æ›´å¤šæ ·æœ¬ï¼Œç‰¹åˆ«æ˜¯è¡¨ç°è¾ƒå·®çš„ç±»åˆ«\n",
    "2. **æ¨¡å‹é›†æˆ**: è®­ç»ƒå¤šä¸ªæ¨¡å‹å¹¶è¿›è¡ŒæŠ•ç¥¨\n",
    "3. **å¤šé±¼æ£€æµ‹**: åŸºäºYOLOç­‰æ¡†æ¶è®­ç»ƒç›®æ ‡æ£€æµ‹æ¨¡å‹\n",
    "4. **å®æ—¶ä¼˜åŒ–**: é’ˆå¯¹æ¨ç†é€Ÿåº¦è¿›è¡Œæ¨¡å‹å‹ç¼©å’Œä¼˜åŒ–\n",
    "\n",
    "---\n",
    "ğŸŸ **æ­å–œå®Œæˆæµ·æ´‹é±¼ç±»è¯†åˆ«æ¨¡å‹çš„è®­ç»ƒï¼** ğŸŸ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
