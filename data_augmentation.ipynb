{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8db339a",
   "metadata": {},
   "source": [
    "# æµ·æ´‹é±¼ç±»æ•°æ®é›†å¢å¼º\n",
    "\n",
    "æœ¬Notebookç”¨äºå¯è§†åŒ–å’Œæ‰§è¡Œæ•°æ®å¢å¼ºç­–ç•¥ï¼Œæå‡æµ·æ´‹é±¼ç±»è¯†åˆ«æ¨¡å‹çš„æ€§èƒ½ã€‚\n",
    "\n",
    "## ç›®æ ‡\n",
    "1. å¯è§†åŒ–ä¸åŒçš„æ•°æ®å¢å¼ºæ•ˆæœ\n",
    "2. ç”Ÿæˆå¢å¼ºåçš„æ•°æ®é›†\n",
    "3. åˆ†æå¢å¼ºç­–ç•¥å¯¹æ¨¡å‹è®­ç»ƒçš„å½±å“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89be67ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import functional as F\n",
    "import glob\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"âœ… æ‰€æœ‰åº“å¯¼å…¥æˆåŠŸï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff50d62e",
   "metadata": {},
   "source": [
    "## 1. æ•°æ®é›†æ¢ç´¢\n",
    "\n",
    "é¦–å…ˆåˆ†æåŸå§‹æ•°æ®é›†çš„ç»“æ„å’Œæ ·æœ¬åˆ†å¸ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e940f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°æ®é›†è·¯å¾„\n",
    "dataset_path = \"../dataset\"\n",
    "\n",
    "# è·å–æ‰€æœ‰é±¼ç±»ç±»åˆ«\n",
    "classes = []\n",
    "class_counts = {}\n",
    "\n",
    "if os.path.exists(dataset_path):\n",
    "    for class_name in os.listdir(dataset_path):\n",
    "        class_dir = os.path.join(dataset_path, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            # ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„å›¾ç‰‡æ•°é‡\n",
    "            images = glob.glob(os.path.join(class_dir, \"*.png\")) + \\\n",
    "                    glob.glob(os.path.join(class_dir, \"*.jpg\")) + \\\n",
    "                    glob.glob(os.path.join(class_dir, \"*.jpeg\"))\n",
    "            \n",
    "            if len(images) > 0:\n",
    "                classes.append(class_name)\n",
    "                class_counts[class_name] = len(images)\n",
    "\n",
    "    print(f\"ğŸ” å‘ç° {len(classes)} ä¸ªé±¼ç±»ç±»åˆ«:\")\n",
    "    for i, (class_name, count) in enumerate(sorted(class_counts.items())):\n",
    "        print(f\"{i+1:2d}. {class_name:25s} - {count:3d} å¼ å›¾ç‰‡\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡:\")\n",
    "    print(f\"æ€»ç±»åˆ«æ•°: {len(classes)}\")\n",
    "    print(f\"æ€»å›¾ç‰‡æ•°: {sum(class_counts.values())}\")\n",
    "    print(f\"å¹³å‡æ¯ç±»: {sum(class_counts.values()) / len(classes):.1f} å¼ \")\n",
    "    print(f\"æœ€å¤šå›¾ç‰‡: {max(class_counts.values())} å¼ \")\n",
    "    print(f\"æœ€å°‘å›¾ç‰‡: {min(class_counts.values())} å¼ \")\n",
    "else:\n",
    "    print(\"âŒ æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„è®¾ç½®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae01cbb3",
   "metadata": {},
   "source": [
    "## 2. æ•°æ®å¢å¼ºç­–ç•¥å®šä¹‰\n",
    "\n",
    "å®šä¹‰å¤šç§æ•°æ®å¢å¼ºæ–¹æ³•ï¼ŒåŒ…æ‹¬å‡ ä½•å˜æ¢ã€é¢œè‰²å˜æ¢ç­‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418919f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_augmentations(image, aug_type=\"all\"):\n",
    "    \"\"\"\n",
    "    å¯¹å•å¼ å›¾ç‰‡åº”ç”¨æ•°æ®å¢å¼º\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Imageå¯¹è±¡\n",
    "        aug_type: å¢å¼ºç±»å‹ (\"rotation\", \"flip\", \"color\", \"brightness\", \"contrast\", \"all\")\n",
    "    \n",
    "    Returns:\n",
    "        augmented_image: å¢å¼ºåçš„PIL Imageå¯¹è±¡\n",
    "    \"\"\"\n",
    "    augmented = image.copy()\n",
    "    \n",
    "    if aug_type == \"rotation\" or aug_type == \"all\":\n",
    "        # éšæœºæ—‹è½¬ (-15 to 15 degrees)\n",
    "        angle = random.uniform(-15, 15)\n",
    "        augmented = augmented.rotate(angle, expand=True, fillcolor=(255, 255, 255))\n",
    "    \n",
    "    elif aug_type == \"flip\" or aug_type == \"all\":\n",
    "        # éšæœºæ°´å¹³ç¿»è½¬\n",
    "        if random.random() > 0.5:\n",
    "            augmented = augmented.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    \n",
    "    elif aug_type == \"brightness\" or aug_type == \"all\":\n",
    "        # äº®åº¦è°ƒæ•´\n",
    "        enhancer = ImageEnhance.Brightness(augmented)\n",
    "        factor = random.uniform(0.7, 1.3)\n",
    "        augmented = enhancer.enhance(factor)\n",
    "    \n",
    "    elif aug_type == \"contrast\" or aug_type == \"all\":\n",
    "        # å¯¹æ¯”åº¦è°ƒæ•´\n",
    "        enhancer = ImageEnhance.Contrast(augmented)\n",
    "        factor = random.uniform(0.8, 1.2)\n",
    "        augmented = enhancer.enhance(factor)\n",
    "    \n",
    "    elif aug_type == \"color\" or aug_type == \"all\":\n",
    "        # è‰²å½©é¥±å’Œåº¦è°ƒæ•´\n",
    "        enhancer = ImageEnhance.Color(augmented)\n",
    "        factor = random.uniform(0.8, 1.2)\n",
    "        augmented = enhancer.enhance(factor)\n",
    "    \n",
    "    return augmented\n",
    "\n",
    "# å®šä¹‰å¢å¼ºç­–ç•¥ç»„åˆ\n",
    "augmentation_strategies = {\n",
    "    \"original\": \"åŸå›¾\",\n",
    "    \"rotation\": \"æ—‹è½¬\",\n",
    "    \"flip\": \"ç¿»è½¬\",\n",
    "    \"brightness\": \"äº®åº¦è°ƒæ•´\", \n",
    "    \"contrast\": \"å¯¹æ¯”åº¦è°ƒæ•´\",\n",
    "    \"color\": \"è‰²å½©è°ƒæ•´\"\n",
    "}\n",
    "\n",
    "print(\"âœ… æ•°æ®å¢å¼ºå‡½æ•°å®šä¹‰å®Œæˆï¼\")\n",
    "print(\"æ”¯æŒçš„å¢å¼ºç­–ç•¥:\")\n",
    "for key, desc in augmentation_strategies.items():\n",
    "    print(f\"  - {key}: {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14f9e49",
   "metadata": {},
   "source": [
    "## 3. å¢å¼ºæ•ˆæœå¯è§†åŒ–\n",
    "\n",
    "å±•ç¤ºä¸åŒå¢å¼ºç­–ç•¥å¯¹æ ·æœ¬å›¾ç‰‡çš„æ•ˆæœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4c1bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é€‰æ‹©ä¸€äº›æ ·æœ¬å›¾ç‰‡è¿›è¡Œå¯è§†åŒ–\n",
    "def visualize_augmentations(class_name=None, num_samples=3):\n",
    "    \"\"\"\n",
    "    å¯è§†åŒ–æ•°æ®å¢å¼ºæ•ˆæœ\n",
    "    \"\"\"\n",
    "    if not classes:\n",
    "        print(\"âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„ç±»åˆ«\")\n",
    "        return\n",
    "    \n",
    "    # å¦‚æœæ²¡æœ‰æŒ‡å®šç±»åˆ«ï¼Œéšæœºé€‰æ‹©ä¸€ä¸ª\n",
    "    if class_name is None:\n",
    "        class_name = random.choice(classes)\n",
    "    \n",
    "    if class_name not in classes:\n",
    "        print(f\"âŒ ç±»åˆ« {class_name} ä¸å­˜åœ¨\")\n",
    "        return\n",
    "    \n",
    "    # è·å–è¯¥ç±»åˆ«çš„å›¾ç‰‡\n",
    "    class_dir = os.path.join(dataset_path, class_name)\n",
    "    images = glob.glob(os.path.join(class_dir, \"*.png\")) + \\\n",
    "             glob.glob(os.path.join(class_dir, \"*.jpg\")) + \\\n",
    "             glob.glob(os.path.join(class_dir, \"*.jpeg\"))\n",
    "    \n",
    "    if len(images) == 0:\n",
    "        print(f\"âŒ ç±»åˆ« {class_name} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡\")\n",
    "        return\n",
    "    \n",
    "    # éšæœºé€‰æ‹©æ ·æœ¬å›¾ç‰‡\n",
    "    sample_images = random.sample(images, min(num_samples, len(images)))\n",
    "    \n",
    "    for img_idx, img_path in enumerate(sample_images):\n",
    "        print(f\"\\nğŸ–¼ï¸  æ ·æœ¬ {img_idx + 1}: {os.path.basename(img_path)}\")\n",
    "        \n",
    "        # åŠ è½½åŸå›¾\n",
    "        original_img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # åˆ›å»ºå­å›¾\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        fig.suptitle(f'æ•°æ®å¢å¼ºæ•ˆæœå±•ç¤º - {class_name}', fontsize=16)\n",
    "        \n",
    "        # æ˜¾ç¤ºåŸå›¾å’Œå„ç§å¢å¼ºæ•ˆæœ\n",
    "        aug_types = ['original', 'rotation', 'flip', 'brightness', 'contrast', 'color']\n",
    "        \n",
    "        for i, aug_type in enumerate(aug_types):\n",
    "            row = i // 3\n",
    "            col = i % 3\n",
    "            \n",
    "            if aug_type == 'original':\n",
    "                img_to_show = original_img\n",
    "            else:\n",
    "                img_to_show = apply_augmentations(original_img, aug_type)\n",
    "            \n",
    "            axes[row, col].imshow(img_to_show)\n",
    "            axes[row, col].set_title(f'{augmentation_strategies[aug_type]}', fontsize=12)\n",
    "            axes[row, col].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# æ‰§è¡Œå¯è§†åŒ–\n",
    "if classes:\n",
    "    # é€‰æ‹©ç¬¬ä¸€ä¸ªç±»åˆ«è¿›è¡Œæ¼”ç¤º\n",
    "    demo_class = classes[0]\n",
    "    print(f\"ğŸ¯ æ¼”ç¤ºç±»åˆ«: {demo_class}\")\n",
    "    visualize_augmentations(demo_class, num_samples=1)\n",
    "else:\n",
    "    print(\"âŒ æ— æ³•è¿›è¡Œå¯è§†åŒ–ï¼Œæœªæ‰¾åˆ°æ•°æ®é›†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b5a1dc",
   "metadata": {},
   "source": [
    "## 4. ç”Ÿæˆå¢å¼ºæ•°æ®é›†\n",
    "\n",
    "ä¸ºæ¯ä¸ªç±»åˆ«ç”Ÿæˆå¢å¼ºåçš„å›¾ç‰‡ï¼Œæ‰©å……è®­ç»ƒæ•°æ®é›†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c232ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_augmented_dataset(\n",
    "    source_dir=\"../dataset\", \n",
    "    output_dir=\"../augmented_dataset\",\n",
    "    target_samples_per_class=300,\n",
    "    augmentations_per_image=3\n",
    "):\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆå¢å¼ºæ•°æ®é›†\n",
    "    \n",
    "    Args:\n",
    "        source_dir: åŸå§‹æ•°æ®é›†ç›®å½•\n",
    "        output_dir: è¾“å‡ºç›®å½•\n",
    "        target_samples_per_class: æ¯ä¸ªç±»åˆ«çš„ç›®æ ‡æ ·æœ¬æ•°\n",
    "        augmentations_per_image: æ¯å¼ åŸå›¾ç”Ÿæˆçš„å¢å¼ºå›¾æ•°é‡\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(source_dir):\n",
    "        print(f\"âŒ æºç›®å½•ä¸å­˜åœ¨: {source_dir}\")\n",
    "        return\n",
    "    \n",
    "    # åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(f\"ğŸš€ å¼€å§‹ç”Ÿæˆå¢å¼ºæ•°æ®é›†...\")\n",
    "    print(f\"ğŸ“ æºç›®å½•: {source_dir}\")\n",
    "    print(f\"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}\")\n",
    "    print(f\"ğŸ¯ ç›®æ ‡: æ¯ç±» {target_samples_per_class} å¼ å›¾ç‰‡\")\n",
    "    print(f\"ğŸ”„ æ¯å¼ åŸå›¾ç”Ÿæˆ {augmentations_per_image} å¼ å¢å¼ºå›¾\")\n",
    "    \n",
    "    total_generated = 0\n",
    "    \n",
    "    for class_name in classes:\n",
    "        print(f\"\\nğŸ“‚ å¤„ç†ç±»åˆ«: {class_name}\")\n",
    "        \n",
    "        # åˆ›å»ºç±»åˆ«è¾“å‡ºç›®å½•\n",
    "        class_output_dir = os.path.join(output_dir, class_name)\n",
    "        Path(class_output_dir).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # è·å–åŸå§‹å›¾ç‰‡\n",
    "        class_input_dir = os.path.join(source_dir, class_name)\n",
    "        original_images = glob.glob(os.path.join(class_input_dir, \"*.png\")) + \\\n",
    "                         glob.glob(os.path.join(class_input_dir, \"*.jpg\")) + \\\n",
    "                         glob.glob(os.path.join(class_input_dir, \"*.jpeg\"))\\n        \n",
    "        if len(original_images) == 0:\n",
    "            print(f\"  âš ï¸ è·³è¿‡ {class_name}ï¼Œæ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  ğŸ“Š åŸå§‹å›¾ç‰‡: {len(original_images)} å¼ \")\n",
    "        \n",
    "        generated_count = 0\n",
    "        \n",
    "        # é¦–å…ˆå¤åˆ¶åŸå§‹å›¾ç‰‡\n",
    "        for i, img_path in enumerate(original_images):\n",
    "            if generated_count >= target_samples_per_class:\n",
    "                break\n",
    "                \n",
    "            # å¤åˆ¶åŸå›¾\n",
    "            img_name = f\"{class_name}_original_{i:04d}.png\"\n",
    "            output_path = os.path.join(class_output_dir, img_name)\n",
    "            \n",
    "            original_img = Image.open(img_path).convert('RGB')\n",
    "            original_img.save(output_path)\n",
    "            generated_count += 1\n",
    "            \n",
    "            # ç”Ÿæˆå¢å¼ºå›¾ç‰‡\n",
    "            for aug_idx in range(augmentations_per_image):\n",
    "                if generated_count >= target_samples_per_class:\n",
    "                    break\n",
    "                \n",
    "                # éšæœºé€‰æ‹©å¢å¼ºç­–ç•¥\n",
    "                aug_strategies = ['rotation', 'flip', 'brightness', 'contrast', 'color']\n",
    "                selected_aug = random.choice(aug_strategies)\n",
    "                \n",
    "                # åº”ç”¨å¢å¼º\n",
    "                augmented_img = apply_augmentations(original_img, selected_aug)\n",
    "                \n",
    "                # ä¿å­˜å¢å¼ºå›¾ç‰‡\n",
    "                aug_img_name = f\"{class_name}_aug_{selected_aug}_{i:04d}_{aug_idx:02d}.png\"\n",
    "                aug_output_path = os.path.join(class_output_dir, aug_img_name)\n",
    "                augmented_img.save(aug_output_path)\n",
    "                generated_count += 1\n",
    "        \n",
    "        print(f\"  âœ… ç”Ÿæˆå›¾ç‰‡: {generated_count} å¼ \")\n",
    "        total_generated += generated_count\n",
    "    \n",
    "    print(f\"\\nğŸ‰ æ•°æ®å¢å¼ºå®Œæˆ!\")\n",
    "    print(f\"ğŸ“Š æ€»è®¡ç”Ÿæˆ: {total_generated} å¼ å›¾ç‰‡\")\n",
    "    print(f\"ğŸ“ ä¿å­˜ä½ç½®: {output_dir}\")\n",
    "    \n",
    "    return output_dir\n",
    "\n",
    "# é…ç½®å‚æ•°\n",
    "AUGMENTED_OUTPUT_DIR = \"../augmented_dataset\"\n",
    "TARGET_SAMPLES = 200  # æ¯ä¸ªç±»åˆ«ç›®æ ‡æ ·æœ¬æ•°\n",
    "AUG_PER_IMAGE = 2     # æ¯å¼ åŸå›¾ç”Ÿæˆçš„å¢å¼ºå›¾æ•°é‡\n",
    "\n",
    "print(\"âš™ï¸  æ•°æ®å¢å¼ºé…ç½®:\")\n",
    "print(f\"   è¾“å‡ºç›®å½•: {AUGMENTED_OUTPUT_DIR}\")\n",
    "print(f\"   æ¯ç±»ç›®æ ‡æ ·æœ¬æ•°: {TARGET_SAMPLES}\")\n",
    "print(f\"   æ¯å¼ åŸå›¾å¢å¼ºæ•°: {AUG_PER_IMAGE}\")\n",
    "print(\"\\nå¦‚éœ€å¼€å§‹ç”Ÿæˆå¢å¼ºæ•°æ®é›†ï¼Œè¯·è¿è¡Œä¸‹ä¸€ä¸ªå•å…ƒæ ¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fbd0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰§è¡Œæ•°æ®å¢å¼ºï¼ˆå–æ¶ˆæ³¨é‡Šä¸‹é¢çš„ä»£ç æ¥æ‰§è¡Œï¼‰\n",
    "# è­¦å‘Šï¼šè¿™å°†ç”Ÿæˆå¤§é‡æ–‡ä»¶ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´\n",
    "\n",
    "# æ‰§è¡Œæ•°æ®å¢å¼º\n",
    "if classes and len(classes) > 0:\n",
    "    print(\"ğŸš€ å¼€å§‹æ‰§è¡Œæ•°æ®å¢å¼º...\")\n",
    "    \n",
    "    # ç”Ÿæˆå¢å¼ºæ•°æ®é›†\n",
    "    augmented_dir = generate_augmented_dataset(\n",
    "        source_dir=dataset_path,\n",
    "        output_dir=AUGMENTED_OUTPUT_DIR,\n",
    "        target_samples_per_class=TARGET_SAMPLES,\n",
    "        augmentations_per_image=AUG_PER_IMAGE\n",
    "    )\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ å¢å¼ºæ•°æ®é›†ç»Ÿè®¡:\")\n",
    "    if os.path.exists(augmented_dir):\n",
    "        for class_name in os.listdir(augmented_dir):\n",
    "            class_dir = os.path.join(augmented_dir, class_name)\n",
    "            if os.path.isdir(class_dir):\n",
    "                count = len([f for f in os.listdir(class_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "                print(f\"  {class_name}: {count} å¼ å›¾ç‰‡\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ æ— æ³•æ‰§è¡Œæ•°æ®å¢å¼ºï¼Œè¯·æ£€æŸ¥æ•°æ®é›†è·¯å¾„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1f5fb2",
   "metadata": {},
   "source": [
    "## 5. PyTorchæ•°æ®å¢å¼ºé›†æˆ\n",
    "\n",
    "å°†å¢å¼ºç­–ç•¥é›†æˆåˆ°PyTorchè®­ç»ƒç®¡é“ä¸­ï¼Œå®ç°åŠ¨æ€æ•°æ®å¢å¼ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4d6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰é€‚ç”¨äºè®­ç»ƒçš„PyTorchå˜æ¢\n",
    "def get_training_transforms():\n",
    "    \"\"\"\n",
    "    è·å–è®­ç»ƒæ—¶çš„æ•°æ®å¢å¼ºå˜æ¢\n",
    "    \"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.2,\n",
    "            contrast=0.2,\n",
    "            saturation=0.2,\n",
    "            hue=0.1\n",
    "        ),\n",
    "        transforms.RandomAffine(\n",
    "            degrees=0,\n",
    "            translate=(0.1, 0.1),\n",
    "            scale=(0.9, 1.1)\n",
    "        ),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "def get_validation_transforms():\n",
    "    \"\"\"\n",
    "    è·å–éªŒè¯/æµ‹è¯•æ—¶çš„å˜æ¢ï¼ˆä¸åŒ…å«éšæœºå¢å¼ºï¼‰\n",
    "    \"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "# åˆ›å»ºå˜æ¢å®ä¾‹\n",
    "train_transform = get_training_transforms()\n",
    "val_transform = get_validation_transforms()\n",
    "\n",
    "print(\"âœ… PyTorchæ•°æ®å¢å¼ºå˜æ¢å·²å®šä¹‰\")\n",
    "print(\"\\nğŸ”§ è®­ç»ƒå˜æ¢åŒ…æ‹¬:\")\n",
    "print(\"  - å›¾åƒè°ƒæ•´å¤§å° (224x224)\")\n",
    "print(\"  - éšæœºæ°´å¹³ç¿»è½¬ (50%æ¦‚ç‡)\")\n",
    "print(\"  - éšæœºæ—‹è½¬ (Â±15åº¦)\")\n",
    "print(\"  - é¢œè‰²æŠ–åŠ¨ (äº®åº¦ã€å¯¹æ¯”åº¦ã€é¥±å’Œåº¦ã€è‰²è°ƒ)\")\n",
    "print(\"  - éšæœºä»¿å°„å˜æ¢ (å¹³ç§»ã€ç¼©æ”¾)\")\n",
    "print(\"  - æ ‡å‡†åŒ– (ImageNetå‡å€¼å’Œæ ‡å‡†å·®)\")\n",
    "\n",
    "print(\"\\nğŸ”§ éªŒè¯å˜æ¢åŒ…æ‹¬:\")\n",
    "print(\"  - å›¾åƒè°ƒæ•´å¤§å° (224x224)\")  \n",
    "print(\"  - æ ‡å‡†åŒ– (ImageNetå‡å€¼å’Œæ ‡å‡†å·®)\")\n",
    "\n",
    "# å±•ç¤ºå˜æ¢æ•ˆæœ\n",
    "if classes and len(classes) > 0:\n",
    "    print(f\"\\nğŸ¯ æ¼”ç¤ºå˜æ¢æ•ˆæœ - ä½¿ç”¨ç±»åˆ«: {classes[0]}\")\n",
    "    \n",
    "    # è·å–ä¸€å¼ æ ·æœ¬å›¾ç‰‡\n",
    "    class_dir = os.path.join(dataset_path, classes[0])\n",
    "    sample_images = glob.glob(os.path.join(class_dir, \"*.png\"))[:1]\n",
    "    \n",
    "    if sample_images:\n",
    "        sample_img_path = sample_images[0]\n",
    "        original_img = Image.open(sample_img_path).convert('RGB')\n",
    "        \n",
    "        # åº”ç”¨å˜æ¢å¹¶å¯è§†åŒ–\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        # åŸå›¾\n",
    "        axes[0].imshow(original_img)\n",
    "        axes[0].set_title('åŸå›¾', fontsize=12)\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # è®­ç»ƒå˜æ¢ (éœ€è¦è½¬æ¢å›PILæ˜¾ç¤º)\n",
    "        train_tensor = train_transform(original_img)\n",
    "        # åæ ‡å‡†åŒ–ç”¨äºæ˜¾ç¤º\n",
    "        inv_normalize = transforms.Normalize(\n",
    "            mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "            std=[1/0.229, 1/0.224, 1/0.225]\n",
    "        )\n",
    "        train_img_display = inv_normalize(train_tensor)\n",
    "        train_img_display = torch.clamp(train_img_display, 0, 1)\n",
    "        axes[1].imshow(train_img_display.permute(1, 2, 0))\n",
    "        axes[1].set_title('è®­ç»ƒå˜æ¢å', fontsize=12)\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        # éªŒè¯å˜æ¢\n",
    "        val_tensor = val_transform(original_img)\n",
    "        val_img_display = inv_normalize(val_tensor)\n",
    "        val_img_display = torch.clamp(val_img_display, 0, 1)\n",
    "        axes[2].imshow(val_img_display.permute(1, 2, 0))\n",
    "        axes[2].set_title('éªŒè¯å˜æ¢å', fontsize=12)\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"ğŸ” å˜æ¢åå¼ é‡å½¢çŠ¶: {train_tensor.shape}\")\n",
    "else:\n",
    "    print(\"âŒ æ— æ³•æ¼”ç¤ºå˜æ¢æ•ˆæœï¼Œæœªæ‰¾åˆ°æ•°æ®é›†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06072df3",
   "metadata": {},
   "source": [
    "## 6. æ€»ç»“ä¸å»ºè®®\n",
    "\n",
    "### ğŸ“Š æ•°æ®å¢å¼ºæ•ˆæœåˆ†æ\n",
    "\n",
    "é€šè¿‡æœ¬Notebookï¼Œæˆ‘ä»¬å®ç°äº†ï¼š\n",
    "\n",
    "1. **ç¦»çº¿æ•°æ®å¢å¼º**: é¢„ç”Ÿæˆå¢å¼ºå›¾ç‰‡ï¼Œæ‰©å……æ•°æ®é›†è§„æ¨¡\n",
    "2. **åœ¨çº¿æ•°æ®å¢å¼º**: PyTorchè®­ç»ƒæ—¶åŠ¨æ€åº”ç”¨å˜æ¢\n",
    "3. **å¯è§†åŒ–å¯¹æ¯”**: ç›´è§‚å±•ç¤ºä¸åŒå¢å¼ºç­–ç•¥çš„æ•ˆæœ\n",
    "\n",
    "### ğŸ¯ è®­ç»ƒå»ºè®®\n",
    "\n",
    "1. **æ•°æ®å¢å¼ºç­–ç•¥**:\n",
    "   - ä½¿ç”¨é€‚åº¦çš„æ—‹è½¬å’Œç¿»è½¬æ¥å¢åŠ å‡ ä½•å˜åŒ–\n",
    "   - é¢œè‰²æŠ–åŠ¨å¸®åŠ©æ¨¡å‹é€‚åº”ä¸åŒå…‰ç…§æ¡ä»¶\n",
    "   - é¿å…è¿‡åº¦å¢å¼ºå¯¼è‡´å›¾ç‰‡å¤±çœŸ\n",
    "\n",
    "2. **è®­ç»ƒä¼˜åŒ–**:\n",
    "   - ç»“åˆé¢„å¢å¼ºæ•°æ®é›†å’ŒåŠ¨æ€å¢å¼º\n",
    "   - åœ¨éªŒè¯é›†ä¸Šä¸ä½¿ç”¨éšæœºå¢å¼º\n",
    "   - ç›‘æ§è¿‡æ‹Ÿåˆï¼Œé€‚å½“è°ƒæ•´å¢å¼ºå¼ºåº¦\n",
    "\n",
    "3. **æ¨¡å‹é€‰æ‹©**:\n",
    "   - å»ºè®®ä½¿ç”¨é¢„è®­ç»ƒçš„ResNet50æˆ–EfficientNet\n",
    "   - åˆ©ç”¨è¿ç§»å­¦ä¹ åŠ é€Ÿè®­ç»ƒ\n",
    "   - æ ¹æ®æ•°æ®é›†å¤§å°è°ƒæ•´å­¦ä¹ ç‡\n",
    "\n",
    "### ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨\n",
    "\n",
    "1. ä½¿ç”¨å¢å¼ºåçš„æ•°æ®é›†è®­ç»ƒæ–°æ¨¡å‹\n",
    "2. å¯¹æ¯”å¢å¼ºå‰åçš„æ¨¡å‹æ€§èƒ½\n",
    "3. æ ¹æ®å®é™…æ•ˆæœè°ƒæ•´å¢å¼ºå‚æ•°\n",
    "4. è€ƒè™‘ä½¿ç”¨æ›´é«˜çº§çš„å¢å¼ºæŠ€æœ¯ï¼ˆå¦‚MixUpã€CutMixç­‰ï¼‰"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
