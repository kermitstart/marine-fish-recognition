# é›†æˆPyTorchæ¨¡å‹åˆ°ç°æœ‰åç«¯ç³»ç»Ÿ
# æ›¿æ¢åŸæœ‰çš„æ¨¡æ‹Ÿé¢„æµ‹ï¼Œä½¿ç”¨è®­ç»ƒå¥½çš„çœŸå®AIæ¨¡å‹

import torch
import torch.nn as nn
from torchvision import transforms, models
from PIL import Image
import json
import os
import numpy as np
import cv2
import shutil
import datetime
from datetime import timedelta
from flask import *

# å¯¼å…¥å¤šé±¼ç±»æ£€æµ‹æ¨¡å—
from multi_fish_detector import MultiFishDetector

UPLOAD_FOLDER = r'./uploads'
ALLOWED_EXTENSIONS = set(['png', 'jpg', 'jpeg'])

app = Flask(__name__)
app.secret_key = 'secret!'
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['SEND_FILE_MAX_AGE_DEFAULT'] = timedelta(seconds=1)

class PyTorchFishClassifier:
    """
    PyTorché±¼ç±»åˆ†ç±»å™¨
    """
    
    def __init__(self, model_path="best_fish_model.pth", config_path="pytorch_dataset_config.json"):
        self.model = None
        self.classes = None
        self.config = None
        self.transform = None
        self.model_loaded = False
        
        try:
            self.load_model(model_path, config_path)
            self.setup_transform()
            self.model_loaded = True
            print("âœ… PyTorché±¼ç±»åˆ†ç±»æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸  PyTorchæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.model_loaded = False
    
    def load_model(self, model_path, config_path):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        # åŠ è½½é…ç½®
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
        
        self.classes = self.config['classes']
        num_classes = self.config['num_classes']
        
        # é‡å»ºæ¨¡å‹ç»“æ„
        self.model = models.resnet50(pretrained=False)
        num_features = self.model.fc.in_features
        self.model.fc = nn.Linear(num_features, num_classes)
        
        # åŠ è½½æƒé‡
        checkpoint = torch.load(model_path, map_location='cpu')
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.eval()
        
        print(f"æ¨¡å‹éªŒè¯å‡†ç¡®ç‡: {checkpoint['val_acc']:.2f}%")
    
    def setup_transform(self):
        """è®¾ç½®å›¾åƒé¢„å¤„ç†"""
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
    
    def predict(self, image_path):
        """
        é¢„æµ‹å›¾åƒç±»åˆ«
        """
        if not self.model_loaded:
            return None, 0.0
        
        try:
            # åŠ è½½å’Œé¢„å¤„ç†å›¾åƒ
            image = Image.open(image_path).convert('RGB')
            image_tensor = self.transform(image).unsqueeze(0)
            
            # é¢„æµ‹
            with torch.no_grad():
                outputs = self.model(image_tensor)
                probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
                confidence, predicted = torch.max(probabilities, 0)
                
                predicted_class = self.classes[predicted.item()]
                confidence_score = confidence.item()
            
            return predicted_class, confidence_score
            
        except Exception as e:
            print(f"é¢„æµ‹é”™è¯¯: {e}")
            return None, 0.0
    
    def get_top_k_predictions(self, image_path, k=3):
        """
        è·å–Top-Ké¢„æµ‹ç»“æœ
        """
        if not self.model_loaded:
            return []
        
        try:
            image = Image.open(image_path).convert('RGB')
            image_tensor = self.transform(image).unsqueeze(0)
            
            with torch.no_grad():
                outputs = self.model(image_tensor)
                probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
                
                # è·å–top-kç»“æœ
                top_k_values, top_k_indices = torch.topk(probabilities, k)
                
                results = []
                for i in range(k):
                    class_name = self.classes[top_k_indices[i].item()]
                    confidence = top_k_values[i].item()
                    results.append({
                        'class': class_name,
                        'confidence': confidence
                    })
                
                return results
                
        except Exception as e:
            print(f"Top-Ké¢„æµ‹é”™è¯¯: {e}")
            return []

# å…¨å±€åˆ†ç±»å™¨å®ä¾‹
fish_classifier = PyTorchFishClassifier()

# åˆå§‹åŒ–å¤šé±¼ç±»æ£€æµ‹å™¨
multi_detector = None

def init_multi_detector():
    """åˆå§‹åŒ–å¤šé±¼ç±»æ£€æµ‹å™¨"""
    global multi_detector
    if fish_classifier.model_loaded and multi_detector is None:
        multi_detector = MultiFishDetector(
            fish_classifier, 
            confidence_threshold=0.5, 
            overlap_threshold=0.3
        )
        print("ğŸ¯ å¤šé±¼ç±»æ£€æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ")

def mock_prediction_fallback():
    """é™çº§åˆ°æ¨¡æ‹Ÿé¢„æµ‹"""
    fish_names = [
        "Abudefduf_vaigiensis", "Acanthurus_nigrofuscus", "Amphiprion_clarkia",
        "Balistapus_undulates", "Canthigaster_valentine", "Chaetodon_lunulatus"
    ]
    import random
    return random.choice(fish_names)

def predict_classification(image_path):
    """
    é±¼ç±»åˆ†ç±»é¢„æµ‹ - ä¼˜å…ˆä½¿ç”¨PyTorchæ¨¡å‹
    """
    if fish_classifier.model_loaded:
        try:
            predicted_class, confidence = fish_classifier.predict(image_path)
            if predicted_class:
                return predicted_class, confidence, True  # Trueè¡¨ç¤ºä½¿ç”¨çœŸå®æ¨¡å‹
        except Exception as e:
            print(f"PyTorché¢„æµ‹å¤±è´¥: {e}")
    
    # é™çº§åˆ°æ¨¡æ‹Ÿé¢„æµ‹
    predicted_class = mock_prediction_fallback()
    confidence = np.random.uniform(0.60, 0.80)
    return predicted_class, confidence, False  # Falseè¡¨ç¤ºä½¿ç”¨æ¨¡æ‹Ÿé¢„æµ‹

def create_segmentation_mock(image_path, filename):
    """
    æ¨¡æ‹Ÿå›¾åƒåˆ†å‰²ï¼ˆç»˜åˆ¶ç®€å•è¾¹æ¡†ï¼‰
    """
    try:
        image = cv2.imread(image_path)
        if image is None:
            return False
        
        height, width = image.shape[:2]
        
        # ç»˜åˆ¶ç®€å•çš„çŸ©å½¢è¾¹æ¡†ä½œä¸º"åˆ†å‰²"ç»“æœ
        margin = min(width, height) // 10
        cv2.rectangle(image, 
                     (margin, margin), 
                     (width - margin, height - margin), 
                     (0, 255, 0), 3)
        
        # æ·»åŠ é¢„æµ‹ä¿¡æ¯
        if fish_classifier.model_loaded:
            top_predictions = fish_classifier.get_top_k_predictions(image_path, k=3)
            if top_predictions:
                text = f"{top_predictions[0]['class']} ({top_predictions[0]['confidence']:.3f})"
                cv2.putText(image, text, (margin, margin - 10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # ä¿å­˜ç»“æœ
        output_path = f'./tmp/draw/{filename}'
        cv2.imwrite(output_path, image)
        return True
        
    except Exception as e:
        print(f"åˆ†å‰²æ¨¡æ‹Ÿé”™è¯¯: {e}")
        shutil.copy(image_path, f'./tmp/draw/{filename}')
        return False

@app.after_request
def after_request(response):
    response.headers['Access-Control-Allow-Origin'] = '*'
    response.headers['Access-Control-Allow-Credentials'] = 'true'
    response.headers['Access-Control-Allow-Methods'] = 'POST'
    response.headers['Access-Control-Allow-Headers'] = 'Content-Type, X-Requested-With'
    return response

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

@app.route('/')
def hello_world():
    status_msg = "PyTorch AI Model" if fish_classifier.model_loaded else "Simulation Mode"
    return jsonify({
        'status': 'Fish Recognition API is running', 
        'message': 'æµ·æ´‹é±¼ç±»è¯†åˆ«ç³»ç»Ÿåç«¯å·²å¯åŠ¨',
        'model_status': status_msg,
        'accuracy': f"{91.62}%" if fish_classifier.model_loaded else "N/A"
    })

@app.route('/upload', methods=['GET', 'POST'])
def upload_file():
    if request.method == 'POST':
        if 'file' not in request.files:
            return jsonify({'status': 0, 'message': 'No file part'})
        
        file = request.files['file']
        print(f"{datetime.datetime.now()} {file.filename}")
        
        if file.filename == '':
            return jsonify({'status': 0, 'message': 'No selected file'})
            
        if file and allowed_file(file.filename):
            src_path = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)
            file.save(src_path)        
            shutil.copy(src_path, './tmp/image')
            image_path = os.path.join('./tmp/image', file.filename)
            print(f"Image saved to: {image_path}")
            
            # è¿›è¡Œåˆ†ç±»é¢„æµ‹
            predicted_class, confidence, is_real_model = predict_classification(image_path)
            print(f"é¢„æµ‹ç»“æœ: {predicted_class} (ç½®ä¿¡åº¦: {confidence:.3f})")
            
            # åˆ›å»ºåˆ†å‰²ç»“æœ
            create_segmentation_mock(image_path, file.filename)
            
            # è·å–è¯¦ç»†é¢„æµ‹ä¿¡æ¯
            top_predictions = []
            if fish_classifier.model_loaded:
                top_predictions = fish_classifier.get_top_k_predictions(image_path, k=3)
            
            return jsonify({
                'status': 1,
                'image_url': f'http://127.0.0.1:5003/tmp/image/{file.filename}',
                'draw_url': f'http://127.0.0.1:5003/tmp/draw/{file.filename}',
                'yucejieguo': predicted_class,
                'confidence': f"{confidence:.3f}",
                'model_status': 'pytorch_resnet50' if is_real_model else 'simulation',
                'accuracy': "91.62%" if is_real_model else "N/A",
                'top_predictions': top_predictions
            })
    
    return jsonify({'status': 0, 'message': 'Invalid request'})

@app.route('/tmp/<path:file>', methods=['GET'])
def show_photo(file):
    if request.method == 'GET':
        if file:
            try:
                image_data = open(f'tmp/{file}', "rb").read()
                response = make_response(image_data)
                response.headers['Content-Type'] = 'image/png'
                return response
            except FileNotFoundError:
                return jsonify({'error': 'File not found'}), 404

@app.route('/model_info', methods=['GET'])
def model_info():
    """è·å–æ¨¡å‹ä¿¡æ¯"""
    info = {
        'model_loaded': fish_classifier.model_loaded,
        'model_type': 'PyTorch ResNet50',
        'num_classes': len(fish_classifier.classes) if fish_classifier.classes else 0,
        'classes': fish_classifier.classes if fish_classifier.classes else [],
        'training_accuracy': "91.62%" if fish_classifier.model_loaded else "N/A"
    }
    return jsonify(info)

@app.route('/multi_detect', methods=['GET', 'POST'])
def multi_fish_detection():
    """
    å¤šé±¼ç±»æ£€æµ‹APIç«¯ç‚¹
    """
    if request.method == 'POST':
        if 'file' not in request.files:
            return jsonify({'status': 0, 'message': 'No file part'})
        
        file = request.files['file']
        print(f"{datetime.datetime.now()} å¤šé±¼ç±»æ£€æµ‹: {file.filename}")
        
        if file.filename == '':
            return jsonify({'status': 0, 'message': 'No selected file'})
            
        if file and allowed_file(file.filename):
            # ä¿å­˜ä¸Šä¼ çš„å›¾ç‰‡
            src_path = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)
            file.save(src_path)
            shutil.copy(src_path, './tmp/image')
            image_path = os.path.join('./tmp/image', file.filename)
            
            # åˆå§‹åŒ–å¤šæ£€æµ‹å™¨ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
            if multi_detector is None:
                init_multi_detector()
            
            if multi_detector and fish_classifier.model_loaded:
                # æ‰§è¡Œå¤šé±¼ç±»æ£€æµ‹
                detections = multi_detector.detect_fish_regions(image_path, max_detections=8)
                
                # ç”Ÿæˆæ£€æµ‹ç»“æœå›¾åƒ
                detection_output = f'./tmp/draw/{file.filename}'
                success = multi_detector.create_opencv_result(image_path, detections, detection_output)
                
                # å‡†å¤‡è¿”å›æ•°æ®
                detection_results = []
                for bbox, class_name, confidence in detections:
                    x1, y1, x2, y2 = bbox
                    detection_results.append({
                        'class': class_name,
                        'confidence': round(confidence, 3),
                        'bbox': {'x1': x1, 'y1': y1, 'x2': x2, 'y2': y2},
                        'center': {'x': (x1+x2)//2, 'y': (y1+y2)//2}
                    })
                
                return jsonify({
                    'status': 1,
                    'image_url': f'http://127.0.0.1:5003/tmp/image/{file.filename}',
                    'detection_url': f'http://127.0.0.1:5003/tmp/draw/{file.filename}',
                    'fish_count': len(detections),
                    'detections': detection_results,
                    'model_status': 'multi_detection_pytorch',
                    'message': f'æ£€æµ‹åˆ° {len(detections)} æ¡é±¼'
                })
            else:
                # é™çº§åˆ°å•é±¼æ£€æµ‹
                predicted_class, confidence, is_real_model = predict_classification(image_path)
                create_segmentation_mock(image_path, file.filename)
                
                return jsonify({
                    'status': 1,
                    'image_url': f'http://127.0.0.1:5003/tmp/image/{file.filename}',
                    'detection_url': f'http://127.0.0.1:5003/tmp/draw/{file.filename}',
                    'fish_count': 1,
                    'detections': [{
                        'class': predicted_class,
                        'confidence': round(confidence, 3),
                        'bbox': {'x1': 0, 'y1': 0, 'x2': 100, 'y2': 100},
                        'center': {'x': 50, 'y': 50}
                    }],
                    'model_status': 'single_classification',
                    'message': f'å•é±¼æ£€æµ‹: {predicted_class}'
                })
    
    return jsonify({'status': 0, 'message': 'Invalid request'})

if __name__ == '__main__':
    # åˆ›å»ºå¿…è¦ç›®å½•
    directories = ['uploads', 'tmp/draw', 'tmp/image', 'tmp/mask']
    for dir_path in directories:
        if not os.path.exists(dir_path):
            os.makedirs(dir_path)
    
    print("ğŸŸ æµ·æ´‹é±¼ç±»è¯†åˆ«ç³»ç»Ÿåç«¯å¯åŠ¨ä¸­...")
    print("ğŸ“¡ åç«¯APIåœ°å€: http://127.0.0.1:5003")
    
    if fish_classifier.model_loaded:
        print("ğŸ¯ ä½¿ç”¨ PyTorch ResNet50 AIæ¨¡å‹")
        print(f"ğŸ“Š æ¨¡å‹å‡†ç¡®ç‡: 91.62%")
        print(f"ğŸ·ï¸  æ”¯æŒç±»åˆ«: {len(fish_classifier.classes)} ç§é±¼ç±»")
        
        # åˆå§‹åŒ–å¤šé±¼ç±»æ£€æµ‹å™¨
        init_multi_detector()
        if multi_detector:
            print("ğŸ” å¤šé±¼ç±»æ£€æµ‹åŠŸèƒ½å·²å¯ç”¨")
    else:
        print("âš ï¸  PyTorchæ¨¡å‹æœªåŠ è½½ï¼Œä½¿ç”¨æ¨¡æ‹Ÿé¢„æµ‹")
    
    app.run(host='127.0.0.1', port=5003, debug=True)
