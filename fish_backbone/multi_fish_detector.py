"""
å¤šé±¼ç±»ç›®æ ‡æ£€æµ‹ç³»ç»Ÿ
ä½¿ç”¨æ»‘çª—æ£€æµ‹ + åˆ†ç±»æ¨¡å‹å®ç°å¤šç›®æ ‡è¯†åˆ«
"""

import torch
import cv2
import numpy as np
from PIL import Image
import json
from torchvision import transforms
import matplotlib.pyplot as plt
import matplotlib.patches as patches

class MultiFishDetector:
    """
    å¤šé±¼ç±»ç›®æ ‡æ£€æµ‹å™¨
    ç»“åˆæ»‘çª—æ£€æµ‹å’Œåˆ†ç±»æ¨¡å‹
    """
    
    def __init__(self, classifier, confidence_threshold=0.6, overlap_threshold=0.3):
        self.classifier = classifier
        self.confidence_threshold = confidence_threshold
        self.overlap_threshold = overlap_threshold
        
        # æ£€æµ‹çª—å£å¤§å°ï¼ˆå¤šå°ºåº¦ï¼‰
        # æ·»åŠ æ›´å¤šå°ºåº¦çš„æ£€æµ‹çª—å£
        self.window_sizes = [
            (48, 48),  # æ›´å°çš„é±¼
            (64, 64),
            (96, 96),
            (128, 128),
            (160, 160),
            (192, 192),  # æ›´å¤§çš„é±¼
        ]

        # self.window_sizes = [
        #     (64, 64),     # è¶…å°é±¼
        #     (96, 96),     # å°é±¼
        #     (128, 128),   # ä¸­ç­‰é±¼
        #     (160, 160),   # å¤§é±¼
        # ]
        
        # æ»‘çª—æ­¥é•¿
        self.stride = 32
        
    def detect_fish_regions(self, image_path, max_detections=10):
        """
        æ£€æµ‹å›¾ç‰‡ä¸­çš„å¤šæ¡é±¼
        è¿”å›: [(bbox, class_name, confidence), ...]
        """
        try:
            # åŠ è½½å›¾åƒ
            image = cv2.imread(image_path)
            if image is None:
                return []
            
            height, width = image.shape[:2]
            detections = []
            
            print(f"ğŸ” å¼€å§‹å¤šé±¼ç±»æ£€æµ‹... å›¾åƒå°ºå¯¸: {width}x{height}")
            
            # å¤šå°ºåº¦æ»‘çª—æ£€æµ‹
            for window_w, window_h in self.window_sizes:
                # è·³è¿‡è¿‡å¤§çš„æ£€æµ‹çª—å£
                if window_w > width or window_h > height:
                    continue
                    
                print(f"  ğŸ” æ£€æµ‹çª—å£: {window_w}x{window_h}")
                
                # æ»‘çª—éå†
                for y in range(0, height - window_h + 1, self.stride):
                    for x in range(0, width - window_w + 1, self.stride):
                        # æå–çª—å£åŒºåŸŸ
                        window = image[y:y+window_h, x:x+window_w]
                        
                        # æ£€æŸ¥çª—å£æ˜¯å¦æœ‰è¶³å¤Ÿçš„å†…å®¹
                        if self._is_valid_window(window):
                            # ä¿å­˜ä¸´æ—¶å›¾ç‰‡è¿›è¡Œåˆ†ç±»
                            temp_path = './tmp/temp_window.jpg'
                            cv2.imwrite(temp_path, window)
                            
                            # ä½¿ç”¨åˆ†ç±»å™¨é¢„æµ‹
                            predicted_class, confidence = self.classifier.predict(temp_path)
                            
                            # å¦‚æœç½®ä¿¡åº¦è¶³å¤Ÿé«˜ï¼Œè®°å½•æ£€æµ‹ç»“æœ
                            if confidence > self.confidence_threshold:
                                bbox = (x, y, x + window_w, y + window_h)
                                detections.append((bbox, predicted_class, confidence))
            
            # éæå¤§å€¼æŠ‘åˆ¶ï¼Œå»é™¤é‡å æ£€æµ‹
            filtered_detections = self._non_max_suppression(detections)
            
            # é™åˆ¶æ£€æµ‹æ•°é‡
            filtered_detections = filtered_detections[:max_detections]
            
            print(f"âœ… æ£€æµ‹å®Œæˆï¼Œå‘ç° {len(filtered_detections)} æ¡é±¼")
            return filtered_detections
            
        except Exception as e:
            print(f"âŒ å¤šé±¼ç±»æ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def _is_valid_window(self, window):
        """
        æ£€æŸ¥çª—å£æ˜¯å¦åŒ…å«æœ‰æ•ˆå†…å®¹
        """
        if window.size == 0:
            return False
        
        # æ£€æŸ¥æ–¹å·®ï¼ˆé¿å…ç©ºç™½åŒºåŸŸï¼‰
        gray = cv2.cvtColor(window, cv2.COLOR_BGR2GRAY)
        variance = np.var(gray)
        
        # å¦‚æœæ–¹å·®å¤ªå°ï¼Œè¯´æ˜åŒºåŸŸè¿‡äºå•è°ƒ
        return variance > 100
    
    def _calculate_iou(self, box1, box2):
        """
        è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„äº¤å¹¶æ¯”(IoU)
        """
        x1_min, y1_min, x1_max, y1_max = box1
        x2_min, y2_min, x2_max, y2_max = box2
        
        # è®¡ç®—äº¤é›†
        inter_x_min = max(x1_min, x2_min)
        inter_y_min = max(y1_min, y2_min)
        inter_x_max = min(x1_max, x2_max)
        inter_y_max = min(y1_max, y2_max)
        
        if inter_x_max <= inter_x_min or inter_y_max <= inter_y_min:
            return 0.0
        
        inter_area = (inter_x_max - inter_x_min) * (inter_y_max - inter_y_min)
        
        # è®¡ç®—å„è‡ªé¢ç§¯
        area1 = (x1_max - x1_min) * (y1_max - y1_min)
        area2 = (x2_max - x2_min) * (y2_max - y2_min)
        
        # è®¡ç®—å¹¶é›†
        union_area = area1 + area2 - inter_area
        
        return inter_area / union_area if union_area > 0 else 0.0
    
    def _non_max_suppression(self, detections):
        """
        éæå¤§å€¼æŠ‘åˆ¶ï¼Œå»é™¤é‡å æ£€æµ‹
        """
        if not detections:
            return []
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        detections.sort(key=lambda x: x[2], reverse=True)
        
        filtered = []
        
        for current in detections:
            current_bbox, current_class, current_conf = current
            
            # æ£€æŸ¥æ˜¯å¦ä¸å·²é€‰æ‹©çš„æ£€æµ‹é‡å 
            is_overlap = False
            for selected in filtered:
                selected_bbox, selected_class, selected_conf = selected
                
                iou = self._calculate_iou(current_bbox, selected_bbox)
                if iou > self.overlap_threshold:
                    is_overlap = True
                    break
            
            if not is_overlap:
                filtered.append(current)
        
        return filtered
    
    def visualize_detections(self, image_path, detections, output_path):
        """
        å¯è§†åŒ–æ£€æµ‹ç»“æœ
        """
        try:
            # è¯»å–åŸå›¾
            image = cv2.imread(image_path)
            if image is None:
                return False
            
            # è½¬æ¢ä¸ºRGBç”¨äºmatplotlib
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            fig, ax = plt.subplots(1, figsize=(12, 8))
            ax.imshow(image_rgb)
            
            # é¢œè‰²åˆ—è¡¨
            colors = ['red', 'blue', 'green', 'yellow', 'purple', 'orange', 'pink', 'cyan']
            
            for i, (bbox, class_name, confidence) in enumerate(detections):
                x1, y1, x2, y2 = bbox
                color = colors[i % len(colors)]
                
                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, 
                                       linewidth=2, edgecolor=color, facecolor='none')
                ax.add_patch(rect)
                
                # æ·»åŠ æ ‡ç­¾
                label = f"{class_name}\n{confidence:.3f}"
                ax.text(x1, y1-10, label, fontsize=10, color=color, 
                       bbox=dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.8))
            
            ax.set_title(f'å¤šé±¼ç±»æ£€æµ‹ç»“æœ - å‘ç° {len(detections)} æ¡é±¼', fontsize=14)
            ax.axis('off')
            
            plt.tight_layout()
            plt.savefig(output_path, dpi=150, bbox_inches='tight')
            plt.close()
            
            return True
            
        except Exception as e:
            print(f"å¯è§†åŒ–å¤±è´¥: {e}")
            return False

    def create_opencv_result(self, image_path, detections, output_path):
        """
        ä½¿ç”¨OpenCVåˆ›å»ºæ£€æµ‹ç»“æœå›¾åƒ
        """
        try:
            image = cv2.imread(image_path)
            if image is None:
                return False
            
            # é¢œè‰²åˆ—è¡¨ (BGRæ ¼å¼)
            colors = [
                (0, 0, 255),    # çº¢è‰²
                (255, 0, 0),    # è“è‰²
                (0, 255, 0),    # ç»¿è‰²
                (0, 255, 255),  # é»„è‰²
                (255, 0, 255),  # ç´«è‰²
                (0, 165, 255),  # æ©™è‰²
                (255, 192, 203), # ç²‰è‰²
                (255, 255, 0),  # é’è‰²
            ]
            
            for i, (bbox, class_name, confidence) in enumerate(detections):
                x1, y1, x2, y2 = bbox
                color = colors[i % len(colors)]
                
                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                cv2.rectangle(image, (x1, y1), (x2, y2), color, 3)
                
                # æ·»åŠ æ ‡ç­¾èƒŒæ™¯
                label = f"{class_name}: {confidence:.3f}"
                (text_w, text_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
                
                # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
                cv2.rectangle(image, (x1, y1-text_h-10), (x1+text_w, y1), color, -1)
                
                # ç»˜åˆ¶æ–‡å­—
                cv2.putText(image, label, (x1, y1-5), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            # æ·»åŠ æ€»ç»“ä¿¡æ¯
            summary = f"Detected {len(detections)} fish"
            cv2.putText(image, summary, (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            
            cv2.imwrite(output_path, image)
            return True
            
        except Exception as e:
            print(f"OpenCVå¯è§†åŒ–å¤±è´¥: {e}")
            return False


def test_multi_fish_detection():
    """
    æµ‹è¯•å¤šé±¼ç±»æ£€æµ‹åŠŸèƒ½
    """
    print("ğŸ§ª æµ‹è¯•å¤šé±¼ç±»æ£€æµ‹åŠŸèƒ½")
    
    # è¿™é‡Œéœ€è¦åŠ è½½å·²æœ‰çš„åˆ†ç±»å™¨
    # å‡è®¾fish_classifierå·²ç»åˆå§‹åŒ–
    from app_pytorch import fish_classifier
    
    if not fish_classifier.model_loaded:
        print("âŒ åˆ†ç±»æ¨¡å‹æœªåŠ è½½")
        return
    
    detector = MultiFishDetector(fish_classifier, confidence_threshold=0.5)
    
    # æµ‹è¯•å›¾ç‰‡è·¯å¾„
    test_image = "./uploads/fish_000004210001_00019.png"
    
    # æ‰§è¡Œæ£€æµ‹
    detections = detector.detect_fish_regions(test_image)
    
    if detections:
        print(f"âœ… æ£€æµ‹ç»“æœ:")
        for i, (bbox, class_name, confidence) in enumerate(detections):
            print(f"  é±¼ {i+1}: {class_name} (ç½®ä¿¡åº¦: {confidence:.3f}) ä½ç½®: {bbox}")
        
        # ç”Ÿæˆå¯è§†åŒ–ç»“æœ
        output_path = "./tmp/multi_fish_detection.jpg"
        detector.create_opencv_result(test_image, detections, output_path)
        print(f"ğŸ“Š æ£€æµ‹ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    else:
        print("âŒ æœªæ£€æµ‹åˆ°é±¼ç±»")


if __name__ == "__main__":
    test_multi_fish_detection()
