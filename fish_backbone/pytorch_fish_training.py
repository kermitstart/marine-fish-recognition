# PyTorchç‰ˆæœ¬çš„é±¼ç±»åˆ†ç±»è®­ç»ƒè„šæœ¬
# é€‚ç”¨äºColabè®­ç»ƒï¼Œä½¿ç”¨ResNet50è¿ç§»å­¦ä¹ 

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from PIL import Image
import os
import json
import glob
import random
import shutil
import time
from sklearn.metrics import accuracy_score, classification_report

class FishDataset(Dataset):
    """
    é±¼ç±»æ•°æ®é›†ç±»
    """
    def __init__(self, data_list, root_dir, transform=None):
        self.data_list = data_list
        self.root_dir = root_dir
        self.transform = transform
    
    def __len__(self):
        return len(self.data_list)
    
    def __getitem__(self, idx):
        img_path, label = self.data_list[idx]
        img_full_path = os.path.join(self.root_dir, img_path)
        
        # åŠ è½½å›¾ç‰‡
        image = Image.open(img_full_path).convert('RGB')
        
        if self.transform:
            image = self.transform(image)
        
        return image, label

def prepare_balanced_dataset(source_dir="../../dataset", 
                           target_dir="./balanced_dataset", 
                           max_samples_per_class=200,
                           test_split=0.2,
                           val_split=0.2):
    """
    å‡†å¤‡å¹³è¡¡çš„æ•°æ®é›†
    """
    print("ğŸ”„ å‡†å¤‡å¹³è¡¡æ•°æ®é›†...")
    
    # æ¸…ç†ç›®æ ‡ç›®å½•
    if os.path.exists(target_dir):
        shutil.rmtree(target_dir)
    
    # åˆ›å»ºç›®å½•
    train_dir = os.path.join(target_dir, "train")
    val_dir = os.path.join(target_dir, "val")
    test_dir = os.path.join(target_dir, "test")
    
    for split_dir in [train_dir, val_dir, test_dir]:
        os.makedirs(split_dir, exist_ok=True)
    
    # è·å–æ‰€æœ‰ç±»åˆ«
    if not os.path.exists(source_dir):
        print(f"âŒ æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {source_dir}")
        return None
    
    all_classes = [d for d in os.listdir(source_dir) 
                   if os.path.isdir(os.path.join(source_dir, d)) and not d.startswith('.')]
    all_classes.sort()
    
    print(f"å‘ç° {len(all_classes)} ä¸ªç±»åˆ«")
    
    # è¿‡æ»¤æ‰æ ·æœ¬å¤ªå°‘çš„ç±»åˆ«
    valid_classes = []
    class_stats = {}
    
    for class_name in all_classes:
        class_dir = os.path.join(source_dir, class_name)
        images = glob.glob(os.path.join(class_dir, "*.png")) + \
                glob.glob(os.path.join(class_dir, "*.jpg")) + \
                glob.glob(os.path.join(class_dir, "*.jpeg"))
        
        # è‡³å°‘éœ€è¦10å¼ å›¾ç‰‡
        if len(images) >= 10:
            valid_classes.append(class_name)
            class_stats[class_name] = len(images)
            print(f"  {class_name}: {len(images)} å¼ ")
        else:
            print(f"  {class_name}: {len(images)} å¼  (è·³è¿‡-æ ·æœ¬å¤ªå°‘)")
    
    print(f"\\næœ‰æ•ˆç±»åˆ«: {len(valid_classes)}")
    
    # å¤„ç†æ¯ä¸ªç±»åˆ«
    train_data = []
    val_data = []
    test_data = []
    
    for i, class_name in enumerate(valid_classes):
        class_dir = os.path.join(source_dir, class_name)
        images = glob.glob(os.path.join(class_dir, "*.png")) + \
                glob.glob(os.path.join(class_dir, "*.jpg")) + \
                glob.glob(os.path.join(class_dir, "*.jpeg"))
        
        random.shuffle(images)
        
        # é™åˆ¶æ¯ç±»æœ€å¤§æ ·æœ¬æ•°
        if len(images) > max_samples_per_class:
            images = images[:max_samples_per_class]
        
        # åˆ’åˆ†æ•°æ®é›†
        n_test = max(1, int(len(images) * test_split))
        n_val = max(1, int(len(images) * val_split))
        n_train = len(images) - n_test - n_val
        
        test_images = images[:n_test]
        val_images = images[n_test:n_test+n_val]
        train_images = images[n_test+n_val:]
        
        # åˆ›å»ºç±»åˆ«ç›®å½•
        for split, split_dir in [("train", train_dir), ("val", val_dir), ("test", test_dir)]:
            class_split_dir = os.path.join(split_dir, class_name)
            os.makedirs(class_split_dir, exist_ok=True)
        
        # å¤åˆ¶æ–‡ä»¶å¹¶è®°å½•
        for img_path in train_images:
            filename = os.path.basename(img_path)
            target_path = os.path.join(train_dir, class_name, filename)
            shutil.copy2(img_path, target_path)
            rel_path = os.path.join("train", class_name, filename)
            train_data.append((rel_path, i))
        
        for img_path in val_images:
            filename = os.path.basename(img_path)
            target_path = os.path.join(val_dir, class_name, filename)
            shutil.copy2(img_path, target_path)
            rel_path = os.path.join("val", class_name, filename)
            val_data.append((rel_path, i))
            
        for img_path in test_images:
            filename = os.path.basename(img_path)
            target_path = os.path.join(test_dir, class_name, filename)
            shutil.copy2(img_path, target_path)
            rel_path = os.path.join("test", class_name, filename)
            test_data.append((rel_path, i))
    
    # ä¿å­˜é…ç½®
    config = {
        "dataset_root": target_dir,
        "num_classes": len(valid_classes),
        "classes": valid_classes,
        "train_samples": len(train_data),
        "val_samples": len(val_data),
        "test_samples": len(test_data),
        "class_stats": class_stats
    }
    
    with open("pytorch_dataset_config.json", "w", encoding="utf-8") as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    print(f"\\nâœ… æ•°æ®é›†å‡†å¤‡å®Œæˆ:")
    print(f"  ç±»åˆ«æ•°: {len(valid_classes)}")
    print(f"  è®­ç»ƒæ ·æœ¬: {len(train_data)}")
    print(f"  éªŒè¯æ ·æœ¬: {len(val_data)}")
    print(f"  æµ‹è¯•æ ·æœ¬: {len(test_data)}")
    
    return config, train_data, val_data, test_data

def create_model(num_classes, pretrained=True):
    """
    åˆ›å»ºResNet50æ¨¡å‹
    """
    model = models.resnet50(pretrained=pretrained)
    
    # æ›¿æ¢æœ€åçš„åˆ†ç±»å±‚
    num_features = model.fc.in_features
    model.fc = nn.Linear(num_features, num_classes)
    
    return model

def train_model(model, train_loader, val_loader, config, 
                epochs=30, lr=0.001, device='cpu'):
    """
    è®­ç»ƒæ¨¡å‹
    """
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒ (è®¾å¤‡: {device})...")
    
    model = model.to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)
    
    best_val_acc = 0.0
    train_history = []
    
    for epoch in range(epochs):
        start_time = time.time()
        
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0
        
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(device), target.to(device)
            
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            _, predicted = torch.max(output.data, 1)
            train_total += target.size(0)
            train_correct += (predicted == target).sum().item()
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for data, target in val_loader:
                data, target = data.to(device), target.to(device)
                output = model(data)
                loss = criterion(output, target)
                
                val_loss += loss.item()
                _, predicted = torch.max(output.data, 1)
                val_total += target.size(0)
                val_correct += (predicted == target).sum().item()
        
        # è®¡ç®—å‡†ç¡®ç‡
        train_acc = 100. * train_correct / train_total
        val_acc = 100. * val_correct / val_total
        
        epoch_time = time.time() - start_time
        
        print(f"Epoch {epoch+1:2d}/{epochs} | "
              f"æ—¶é—´: {epoch_time:.1f}s | "
              f"è®­ç»ƒæŸå¤±: {train_loss/len(train_loader):.4f} | "
              f"è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.2f}% | "
              f"éªŒè¯æŸå¤±: {val_loss/len(val_loader):.4f} | "
              f"éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}%")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_acc': val_acc,
                'config': config
            }, 'best_fish_model.pth')
        
        # è®°å½•è®­ç»ƒå†å²
        train_history.append({
            'epoch': epoch + 1,
            'train_loss': train_loss / len(train_loader),
            'train_acc': train_acc,
            'val_loss': val_loss / len(val_loader),
            'val_acc': val_acc
        })
        
        scheduler.step()
    
    print(f"\\nâœ… è®­ç»ƒå®Œæˆ! æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")
    return train_history

def main():
    """
    ä¸»è®­ç»ƒæµç¨‹
    """
    print("ğŸŸ PyTorch é±¼ç±»åˆ†ç±»è®­ç»ƒç³»ç»Ÿ")
    print("=" * 50)
    
    # è®¾å¤‡é€‰æ‹©
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ•°æ®é¢„å¤„ç†
    print("\\nå‡†å¤‡æ•°æ®é›†...")
    config, train_data, val_data, test_data = prepare_balanced_dataset()
    
    if config is None:
        return
    
    # æ•°æ®å˜æ¢
    train_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(10),
        transforms.ColorJitter(brightness=0.2, contrast=0.2),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    val_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    # åˆ›å»ºæ•°æ®é›†å’ŒåŠ è½½å™¨
    train_dataset = FishDataset(train_data, config['dataset_root'], train_transform)
    val_dataset = FishDataset(val_data, config['dataset_root'], val_transform)
    
    batch_size = 16 if device.type == 'cuda' else 8
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)
    
    # åˆ›å»ºæ¨¡å‹
    print(f"\\nåˆ›å»ºResNet50æ¨¡å‹ ({config['num_classes']} ä¸ªç±»åˆ«)...")
    model = create_model(config['num_classes'])
    
    # è®­ç»ƒæ¨¡å‹
    train_history = train_model(
        model, train_loader, val_loader, config,
        epochs=20,  # å¯ä»¥åœ¨Colabä¸­è°ƒæ•´ä¸ºæ›´å¤šè½®æ•°
        lr=0.001,
        device=device
    )
    
    print("\\nğŸ‰ è®­ç»ƒå®Œæˆ!")
    print("\\nğŸ“‹ åç»­æ­¥éª¤:")
    print("1. æ£€æŸ¥ 'best_fish_model.pth' æ–‡ä»¶")
    print("2. å¯ä»¥åŠ è½½æ¨¡å‹è¿›è¡Œæ¨ç†æµ‹è¯•")
    print("3. è½¬æ¢ä¸ºPaddlePaddleæ ¼å¼(å¯é€‰)")

if __name__ == "__main__":
    main()
